{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LIF_Neuron():\n",
    "\n",
    "    # constant LIF properties\n",
    "    # baseline charge when neuron is fully neutral\n",
    "    baseCharge = 4\n",
    "    # membrane capacitance\n",
    "    C = 1\n",
    "    # time interval for our neuron, based on neuron firing 200 times per sec\n",
    "    dt = 1\n",
    "    # neuron resistance\n",
    "    resistance = 16\n",
    "    # spiking threshold\n",
    "    threshold = 10\n",
    "    # additional charge that results from passing threshold\n",
    "    spike = 1\n",
    "\n",
    "    # dynamic LIF variables\n",
    "    inputCharge = 0\n",
    "    currentCharge = baseCharge\n",
    "\n",
    "    # Constructor takes in initial input charge\n",
    "    def __init__(self):\n",
    "        return\n",
    "\n",
    "    # Every call using .start() or next() will update the neuron charge\n",
    "    # Neuron will check if it should spike\n",
    "    # If it has spiked, we return a 1 and the current charge plus spike\n",
    "    # otherwise we yield a 0 and the baseline charge\n",
    "    def run(self, inputCharge):\n",
    "\n",
    "        # add dV to current charge, dv based on input charge and leak\n",
    "        self.currentCharge += self.dt * (inputCharge - (self.currentCharge / self.resistance)) / self.C\n",
    "\n",
    "        # Check if we have reached the threshold\n",
    "        if self.currentCharge >= self.threshold:\n",
    "            outputCharge = self.currentCharge\n",
    "            # resetting charge and spiking\n",
    "            self.currentCharge = self.baseCharge\n",
    "            return 1, outputCharge + self.spike\n",
    "\n",
    "        else:\n",
    "            return 0, self.baseCharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, NamedTuple, Tuple, Any, Sequence\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial random weights: \n",
      "[0.54437436 0.17496952 0.16234648 0.42984071 0.57617136 0.9733045 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Neuron 0 and 1 are input neurons. Neurons 2 and 3 are hidden layer neurons. Neuron 4 is the output neuron\n",
    "# 2 input neurons, 1 for first num and another for second num\n",
    "# 2 hidden neurons\n",
    "# 1 output neuron, fires high if XOR, fires low if !XOR\n",
    "\n",
    "# Creating random initial weights\n",
    "# Weights represent directed edges in this network:\n",
    "# 0 (0, 2) input0 to first hidden neuron\n",
    "# 1 (1, 2) input1 to first hidden neuron\n",
    "# 2 (0, 3) input0 to second hidden neuron\n",
    "# 3 (1, 3) input1 to second hidden neuron\n",
    "# 4 (2, 4) first hidden neuron to output\n",
    "# 5 (3, 4) second hidden neuron to output\n",
    "weights = np.random.random(6)\n",
    "print(\"Initial random weights: \")\n",
    "print(weights)\n",
    "\n",
    "# hardbound for weights\n",
    "WEIGHT_MAX = 1\n",
    "\n",
    "# Creating constants for our high and low inputs to represent 0 or 1\n",
    "LOW_INPUT = 1\n",
    "HIGH_INPUT = 9\n",
    "\n",
    "# Constants for our weight change\n",
    "ALPHA = .175\n",
    "DECAY = .998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(x,y):\n",
    "        return x+y\n",
    "\n",
    "def sub(x,y):\n",
    "        return x-y\n",
    "\n",
    "def mul(x,y):\n",
    "        return x*y\n",
    "\n",
    "def div(x,y):\n",
    "        return x/y\n",
    "\n",
    "F = [add, sub, mul]#, div]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_operand = 4 #number of operands\n",
    "n_row = 4 #number of rows\n",
    "n_column = 2 #number of columns of internal nodes\n",
    "n_F = len(F) #number of operators\n",
    "\n",
    "def create_node():\n",
    "        internal1 = torch.cat((torch.randint(n_F,(n_row,1)),torch.randint(n_operand,(n_row,n_column))),1)\n",
    "        internal2 = torch.cat((torch.randint(n_F,(n_row,1)),torch.randint(n_row,(n_row,n_column))),1)\n",
    "        internal = torch.cat((internal1,internal2))\n",
    "        return internal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute(S,operand):\n",
    "        pheno = S[0]\n",
    "        i = S[1]\n",
    "        def compute1(i):\n",
    "                operator = F[pheno[i][0]]\n",
    "                output = operator(operand[pheno[i][1]],operand[pheno[i][2]])\n",
    "                return output\n",
    "        if i < n_row:\n",
    "                output = compute1(i)\n",
    "        else:\n",
    "                operator = F[pheno[i][0]]\n",
    "                output = operator(compute1(pheno[i][1]), compute1(pheno[i][2]))\n",
    "        return output\n",
    "\n",
    "def mutation(S):\n",
    "        mu = torch.randn((8,3))#*0.3\n",
    "        #mu = torch.clamp(mu, -1, 1) + 1\n",
    "        mutated_internal = torch.round(S[0]+mu)\n",
    "        l1 = torch.FloatTensor([[0, 0, 0]])\n",
    "        u1 = torch.FloatTensor([[n_F-1, n_operand-1, n_operand-1]]) #[2,2,2]\n",
    "        mutated_internal[:4] = torch.max(torch.min(mutated_internal[:4], u1), l1) #clamp the nodes in the first column within the range [l1, u1]\n",
    "        l2 = torch.FloatTensor([[0, 0, 0]])\n",
    "        u2 = torch.FloatTensor([[n_F-1, n_row-1, n_row-1]]) #[2,3,3] \n",
    "        mutated_internal[4:] = torch.max(torch.min(mutated_internal[4:], u2), l2) #clamp the nodes in the second column within the range [l2, u2]\n",
    "        mutated_internal = mutated_internal.int()\n",
    "        mutated_node_index = torch.randint(len(mutated_internal),(1,1)).item()\n",
    "        mutated_S = [mutated_internal,mutated_node_index]\n",
    "        return mutated_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(S):\n",
    "\n",
    "    inputNeuron0 = LIF_Neuron()\n",
    "    inputNeuron1 = LIF_Neuron()\n",
    "    middleNeuron2 = LIF_Neuron()\n",
    "    middleNeuron3 = LIF_Neuron()\n",
    "    outputNeuron = LIF_Neuron()\n",
    "\n",
    "    # These values simulate a training current that either force or spike or prohibit a spike\n",
    "    neuron2training = 0\n",
    "    neuron3training = 0\n",
    "    neuron4training = 0\n",
    "    FORCE_SPIKE = 1000\n",
    "    PROHIBIT = -2000\n",
    "\n",
    "    \n",
    "    N = 1000\n",
    "    # Train network with this many iterations\n",
    "    for j in range(N):  #1000\n",
    "\n",
    "        # print(\"starting training iteration \", j)\n",
    "        # print(weights)\n",
    "\n",
    "        # Each iteration trains every possible input once\n",
    "        for i in range(4):\n",
    "\n",
    "            # We find the activity in a 100 time unit interval\n",
    "            neuron0output = 0\n",
    "            neuron1output = 0\n",
    "\n",
    "            neuron0activity = 0\n",
    "            neuron1activity = 0\n",
    "            neuron2activity = 0\n",
    "            neuron3activity = 0\n",
    "            neuron4activity = 0\n",
    "\n",
    "            # (0, 0)\n",
    "            if i == 0:\n",
    "                neuron0output = inputNeuron0.run(LOW_INPUT)\n",
    "                neuron1output = inputNeuron1.run(LOW_INPUT)\n",
    "                neuron2training = PROHIBIT\n",
    "                neuron3training = FORCE_SPIKE\n",
    "                neuron4training = PROHIBIT * 2\n",
    "            # (1, 1)\n",
    "            elif i == 1:\n",
    "                neuron0output = inputNeuron0.run(HIGH_INPUT)\n",
    "                neuron1output = inputNeuron1.run(HIGH_INPUT)\n",
    "                neuron2training = FORCE_SPIKE\n",
    "                neuron3training = FORCE_SPIKE\n",
    "                neuron4training = FORCE_SPIKE\n",
    "            # (0, 1)\n",
    "            elif i == 2:\n",
    "                neuron0output = inputNeuron0.run(LOW_INPUT)\n",
    "                neuron1output = inputNeuron1.run(HIGH_INPUT)\n",
    "                neuron2training = FORCE_SPIKE\n",
    "                neuron3training = FORCE_SPIKE\n",
    "                neuron4training = PROHIBIT\n",
    "            # (1, 0)\n",
    "            elif i == 3:\n",
    "                neuron0output = inputNeuron0.run(HIGH_INPUT)\n",
    "                neuron1output = inputNeuron1.run(LOW_INPUT)\n",
    "                neuron2training = FORCE_SPIKE\n",
    "                neuron3training = FORCE_SPIKE\n",
    "                neuron4training = PROHIBIT\n",
    "            #print(i,neuron0output,neuron1output)\n",
    "            \n",
    "            \n",
    "            for k in range(100):\n",
    "                # adds 1 if the neuron spiked, adds 0 otherwise\n",
    "                neuron0activity += neuron0output[0]\n",
    "                neuron1activity += neuron1output[0]\n",
    "\n",
    "                # run the or neuron with current given by input neurons and training value\n",
    "                neuron2charge = neuron0output[1] * weights[0] + neuron1output[1] * weights[1] + neuron2training\n",
    "                neuron2output = middleNeuron2.run(neuron2charge)\n",
    "                neuron2activity += neuron2output[0]\n",
    "\n",
    "                # run the nand neuron with current given by input neurons and training value\n",
    "                neuron3charge = neuron0output[1] * weights[2] + neuron1output[1] * weights[3] + neuron3training\n",
    "                neuron3output = middleNeuron3.run(neuron3charge)\n",
    "                neuron3activity += neuron3output[0]\n",
    "\n",
    "                # run the output neuron with current given by hidden neurons and training value\n",
    "                neuron4charge = neuron2output[1] * weights[4] + neuron3output[1] * weights[5] + neuron4training\n",
    "                neuron4output = outputNeuron.run(neuron4charge)\n",
    "                neuron4activity += neuron4output[0]\n",
    "\n",
    "            \n",
    "            # the activity must be reduced to represent what occurs in one time unit and as a decimal\n",
    "            neuron0activity = neuron0activity / 1000\n",
    "            neuron1activity = neuron1activity / 1000\n",
    "            neuron2activity = neuron2activity / 1000\n",
    "            neuron3activity = neuron3activity / 1000\n",
    "            neuron4activity = neuron4activity / 1000\n",
    "\n",
    "            #print(neuron0activity,neuron1activity,neuron2activity,neuron3activity,neuron4activity)\n",
    "            # weight adjustments\n",
    "            # we now calculate weight adjustments based on activity of each neuron and exponential decay\n",
    "\n",
    "            # print(\"weight adjustments\")\n",
    "\n",
    "            #weight0dw = ALPHA * neuron0activity * neuron2activity - DECAY * weights[0]\n",
    "            # print(weight0dw)\n",
    "            #weights[0] += weight0dw\n",
    "            #weights[0] = ALPHA * neuron0activity * neuron2activity + DECAY * weights[0]\n",
    "            weights[0] = compute(S,[1,ALPHA,neuron0activity,neuron2activity]) + DECAY * weights[0]\n",
    "\n",
    "            #weight1dw = ALPHA * neuron1activity * neuron2activity - DECAY * weights[1]\n",
    "            # print(weight1dw)\n",
    "            #weights[1] += weight1dw\n",
    "            #weights[1] = ALPHA * neuron1activity * neuron2activity + DECAY * weights[1]\n",
    "            weights[1] = compute(S,[1,ALPHA,neuron1activity,neuron2activity]) + DECAY * weights[1]\n",
    "\n",
    "            #weight2dw = ALPHA * neuron0activity * neuron3activity - DECAY * weights[2]\n",
    "            # print(weight2dw)\n",
    "            #weights[2] += weight2dw\n",
    "            #weights[2] = ALPHA * neuron0activity * neuron3activity + DECAY * weights[2]\n",
    "            weights[2] = compute(S,[1,ALPHA,neuron0activity,neuron3activity]) + DECAY * weights[2]\n",
    "\n",
    "            #weight3dw = ALPHA * neuron1activity * neuron3activity - DECAY * weights[3]\n",
    "            # print(weight3dw)\n",
    "            #weights[3] += weight3dw\n",
    "            weights[3] = compute(S,[1,ALPHA,neuron1activity,neuron3activity]) + DECAY * weights[3]\n",
    "\n",
    "            #weight4dw = ALPHA * neuron2activity * neuron4activity - DECAY * weights[4]\n",
    "            # print(weight4dw)\n",
    "            #weights[4] += weight4dw\n",
    "            #weights[4] = ALPHA * neuron2activity * neuron4activity + DECAY * weights[4]\n",
    "            weights[4] = compute(S,[1,ALPHA,neuron2activity,neuron4activity]) + DECAY * weights[4]\n",
    "\n",
    "            #weight5dw = ALPHA * neuron3activity * neuron4activity - DECAY * weights[5]\n",
    "            # print(weight5dw)\n",
    "            #weights[5] += weight5dw\n",
    "            #weights[5] = ALPHA * neuron3activity * neuron4activity + DECAY * weights[5]\n",
    "            weights[5] = compute(S,[1,ALPHA,neuron3activity,neuron4activity]) + DECAY * weights[5]\n",
    "\n",
    "            # Bounding our weights\n",
    "            for l in range(len(weights)):\n",
    "                if weights[l] >= WEIGHT_MAX:\n",
    "                    weights[l] = WEIGHT_MAX\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs the input 100 times to shown activity in a 100 time unit interval\n",
    "# If this gate is working, we should see a significant amount of spikes when we expect XOR to return 1\n",
    "# and far fewer spikes when we expect XOR to return 0\n",
    "def test(x, y):\n",
    "\n",
    "    inputNeuron0 = LIF_Neuron()\n",
    "    inputNeuron1 = LIF_Neuron()\n",
    "    middleNeuron2 = LIF_Neuron()\n",
    "    middleNeuron3 = LIF_Neuron()\n",
    "    outputNeuron = LIF_Neuron()\n",
    "\n",
    "    totalSpikes = 0\n",
    "\n",
    "    for i in range(1000):\n",
    "\n",
    "        neuron0current = 0\n",
    "        neuron1current = 0\n",
    "\n",
    "        if x == 0 and y == 0:\n",
    "            neuron0current = inputNeuron0.run(LOW_INPUT)[1]\n",
    "            neuron1current = inputNeuron1.run(LOW_INPUT)[1]\n",
    "        elif x == 0 and y == 1:\n",
    "            neuron0current = inputNeuron0.run(LOW_INPUT)[1]\n",
    "            neuron1current = inputNeuron1.run(HIGH_INPUT)[1]\n",
    "        elif x == 1 and y == 0:\n",
    "            neuron0current = inputNeuron0.run(HIGH_INPUT)[1]\n",
    "            neuron1current = inputNeuron1.run(LOW_INPUT)[1]\n",
    "        elif x == 1 and y == 1:\n",
    "            neuron0current = inputNeuron0.run(HIGH_INPUT)[1]\n",
    "            neuron1current = inputNeuron1.run(HIGH_INPUT)[1]\n",
    "\n",
    "        neuron2output = middleNeuron2.run(neuron0current * weights[0] + neuron1current * weights[1])\n",
    "        neuron2current = neuron2output[1]\n",
    "\n",
    "        neuron3output = middleNeuron3.run(14 - (neuron0current * weights[2] + neuron1current * weights[3]))\n",
    "        neuron3current = neuron3output[1]\n",
    "\n",
    "        neuron4spikes = outputNeuron.run(neuron2current * weights[4] + neuron3current * weights[5])[0]\n",
    "        totalSpikes += neuron4spikes\n",
    "    \n",
    "    if totalSpikes > 400:\n",
    "        output = 1\n",
    "    else:\n",
    "        output = 0\n",
    "\n",
    "    # TESTING ONLY REMOVE LATER\n",
    "    return totalSpikes, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy():\n",
    "    prediction = [test(0, 0)[1],test(0, 1)[1],test(1, 0)[1],test(1, 1)[1]]\n",
    "    label = [0,1,1,0]\n",
    "    return sum(abs(np.array(prediction)-np.array(label)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2]\n"
     ]
    }
   ],
   "source": [
    "#opernad = [1,alpha,pre,post]\n",
    "internal1 = torch.IntTensor([[2,0,1],[2,2,3],[1,1,1],[0,0,0],[2,0,1],[0,0,0],[0,0,0],[0,0,0]])\n",
    "node_index1 = torch.randint(len(internal1),(1,1)).item()\n",
    "#node_index1 = 4\n",
    "S1 = [internal1,node_index1]\n",
    "internal2 = create_node()\n",
    "node_index2 = torch.randint(len(internal2),(1,1)).item()\n",
    "S2 = [internal2,node_index2]\n",
    "Stab = [S1,S2]\n",
    "train(S1)\n",
    "L1 = accuracy()\n",
    "weights = np.random.random(6)\n",
    "train(S2)\n",
    "L2 = accuracy()\n",
    "weights = np.random.random(6)\n",
    "Ltab = [L1,L2]\n",
    "print(Ltab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 2]\n",
      "[2, 2]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 3, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 1, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 3, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 1]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 1, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 1, 2]\n",
      "[1, 1]\n",
      "[1, 1, 3, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n",
      "[1, 1, 2, 2, 2, 2]\n",
      "[1, 1]\n"
     ]
    }
   ],
   "source": [
    "gen = 501\n",
    "for g in range(gen):\n",
    "    Smutab = []\n",
    "    Smu11 = mutation(Stab[0])\n",
    "    Smu12 = mutation(Stab[0])\n",
    "    Smu21 = mutation(Stab[1])\n",
    "    Smu22 = mutation(Stab[1])\n",
    "    Smutab.append(Smu11)\n",
    "    Smutab.append(Smu12)\n",
    "    Smutab.append(Smu21)\n",
    "    Smutab.append(Smu22)\n",
    "    #print(Smutab)\n",
    "    Lmutab = []\n",
    "    train(Smu11)\n",
    "    weights = np.random.random(6)\n",
    "    Lmutab.append(accuracy())\n",
    "    train(Smu12)\n",
    "    weights = np.random.random(6)\n",
    "    Lmutab.append(accuracy())\n",
    "    train(Smu21)\n",
    "    weights = np.random.random(6)\n",
    "    Lmutab.append(accuracy())\n",
    "    train(Smu22)\n",
    "    weights = np.random.random(6)\n",
    "    Lmutab.append(accuracy())\n",
    "    #print(Lmutab)\n",
    "    Ljointtab = Ltab + Lmutab\n",
    "    Sjointtab = Stab + Smutab\n",
    "    good_index = heapq.nsmallest(2,range(len(Ljointtab)), Ljointtab.__getitem__)\n",
    "    Stab = [Sjointtab[m] for m in good_index]\n",
    "    Ltab = [Ljointtab[n] for n in good_index]\n",
    "    if g % 10 == 0:\n",
    "        print(Ljointtab)\n",
    "        print(Ltab)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[tensor([[2, 0, 0],\n",
      "        [2, 2, 2],\n",
      "        [2, 3, 1],\n",
      "        [0, 0, 0],\n",
      "        [2, 0, 2],\n",
      "        [0, 0, 1],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]], dtype=torch.int32), 7], [tensor([[2, 3, 3],\n",
      "        [2, 1, 2],\n",
      "        [1, 1, 0],\n",
      "        [1, 0, 0],\n",
      "        [0, 0, 2],\n",
      "        [1, 0, 3],\n",
      "        [1, 0, 3],\n",
      "        [0, 1, 3]], dtype=torch.int32), 1]]\n"
     ]
    }
   ],
   "source": [
    "print(Stab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST==============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained weights\n",
      "[0.40284207 0.40272383 0.43791171 0.43766393 0.1451231  0.17289226]\n",
      "\n",
      "Finding spikes rates in a 100 time unit interval\n",
      "Expected results for a working xor network is significant spike rate difference between 0 and 1 outputs.\n",
      "(0, 0): (363, 0)\n",
      "(0, 1): (500, 1)\n",
      "(1, 0): (500, 1)\n",
      "(1, 1): (375, 0)\n"
     ]
    }
   ],
   "source": [
    "train(S1)\n",
    "print(\"Trained weights\")\n",
    "print(weights)\n",
    "\n",
    "print(\"\\nFinding spikes rates in a 100 time unit interval\")\n",
    "print(\"Expected results for a working xor network is significant spike rate difference between 0 and 1 outputs.\")\n",
    "print(\"(0, 0): \" + str(test(0, 0)))\n",
    "print(\"(0, 1): \" + str(test(0, 1)))\n",
    "print(\"(1, 0): \" + str(test(1, 0)))\n",
    "print(\"(1, 1): \" + str(test(1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = [0, 0, 0, 0]\n",
    "label = [0, 1, 1, 0]\n",
    "a = abs(np.array(prediction)-np.array(label))\n",
    "sum(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
