{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, NamedTuple, Tuple, Any, Sequence\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import heapq\n",
    "import math\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spiking network with the LIF neuron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikeFunction(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Spiking function with rectangular gradient.\n",
    "    Source: https://www.frontiersin.org/articles/10.3389/fnins.2018.00331/full\n",
    "    Implementation: https://github.com/combra-lab/pop-spiking-deep-rl/blob/main/popsan_drl/popsan_td3/popsan.py\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx: Any, v: torch.Tensor) -> torch.Tensor:\n",
    "        ctx.save_for_backward(v)  # save voltage - thresh for backwards pass\n",
    "        return v.gt(0.0).float()\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx: Any, grad_output: torch.Tensor) -> Tuple[torch.Tensor, ...]:\n",
    "        v, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        spike_pseudo_grad = (v.abs() < 0.5).float()  # 0.5 is the width of the rectangle\n",
    "        return grad_input * spike_pseudo_grad, None  # ensure a tuple is returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for LIF state\n",
    "class LIFState(NamedTuple):\n",
    "    z: torch.Tensor\n",
    "    v: torch.Tensor\n",
    "    i: torch.Tensor\n",
    "\n",
    "class LIF(nn.Module):\n",
    "    \"\"\"\n",
    "    Leaky-integrate-and-fire neuron with learnable parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size: int):\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        # Initialize all parameters randomly as U(0, 1)\n",
    "        self.i_decay = torch.rand(size) #self.i_decay = nn.Parameter(torch.rand(size))\n",
    "        self.v_decay = torch.rand(size)\n",
    "        self.thresh = torch.rand(size)\n",
    "        self.spike = SpikeFunction.apply  # spike function\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        synapse: nn.Module,\n",
    "        z: torch.Tensor,\n",
    "        state: Optional[LIFState] = None,\n",
    "    ) -> Tuple[torch.Tensor, LIFState]:\n",
    "        # Previous state\n",
    "        if state is None:\n",
    "            state = LIFState(\n",
    "                z=torch.zeros_like(synapse(z)),\n",
    "                v=torch.zeros_like(synapse(z)),\n",
    "                i=torch.zeros_like(synapse(z)),\n",
    "            )\n",
    "        # Update state\n",
    "        i = state.i * self.i_decay + synapse(z)\n",
    "        #print(self.i_decay)\n",
    "        #print(synapse(z))\n",
    "        v = state.v * self.v_decay * (1.0 - state.z) + i\n",
    "        z = self.spike(v - self.thresh)\n",
    "\n",
    "        return z, LIFState(z, v, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingMLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Spiking network with LIF neuron model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sizes: Sequence[int]):\n",
    "        super().__init__()\n",
    "        self.sizes = sizes\n",
    "        self.spike = SpikeFunction.apply\n",
    "\n",
    "        # Define layers\n",
    "        self.synapses = nn.ModuleList()\n",
    "        self.neurons = nn.ModuleList()\n",
    "        self.states = []\n",
    "        # Loop over current (accessible with 'size') and next (accessible with 'sizes[i]') element\n",
    "        for i, size in enumerate(sizes[:-1], start=1):\n",
    "            # Parameters of synapses and neurons are randomly initialized\n",
    "            self.synapses.append(nn.Linear(size, sizes[i], bias=False))\n",
    "            self.neurons.append(LIF(sizes[i]))\n",
    "            self.states.append(None)\n",
    "           \n",
    "\n",
    "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        for i, (neuron, synapse) in enumerate(zip(self.neurons, self.synapses)):\n",
    "            z, self.states[i] = neuron(synapse, z, self.states[i])\n",
    "        return z\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resetting states when you're done is very important!\n",
    "        \"\"\"\n",
    "        for i, _ in enumerate(self.states):\n",
    "            self.states[i] = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]])\n",
      "tensor([0., 1., 1., 0.])\n"
     ]
    }
   ],
   "source": [
    "# Data and labels\n",
    "#samples = 50 #10000\n",
    "#x = torch.randint(2, (samples, 2)).float()\n",
    "x = torch.Tensor([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = (x.sum(-1) == 1).float()\n",
    "print(x)\n",
    "print(y)\n",
    "#print(f\"Class imbalance: {y.sum() / y.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 10\n",
    "\n",
    "def encoding(inp):\n",
    "    #height, width = x.shape\n",
    "    inp = inp.unsqueeze(-1)\n",
    "    rate = 0.7\n",
    "    return (torch.rand((len(inp),T))<(inp*rate+0.1)).float()\n",
    "    \n",
    "#test = encoding(x[3])  \n",
    "#print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward(output,label):\n",
    "    if output == 0 and label == 0:\n",
    "        R = 1\n",
    "    if output == 1 and label == 1:\n",
    "        R = 1\n",
    "    if output == 1 and label == 0:\n",
    "        R = -1 \n",
    "    if output == 0 and label == 1:\n",
    "        R = -1\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpikingMLP(\n",
       "  (synapses): ModuleList(\n",
       "    (0): Linear(in_features=2, out_features=5, bias=False)\n",
       "    (1): Linear(in_features=5, out_features=1, bias=False)\n",
       "  )\n",
       "  (neurons): ModuleList(\n",
       "    (0): LIF()\n",
       "    (1): LIF()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizes = [2,5,1]\n",
    "snn = SpikingMLP(sizes)\n",
    "snn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RSTDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 1\n",
    "taup = 20\n",
    "taum = 20\n",
    "Ap = 2\n",
    "Am = -1\n",
    "tauz = 25\n",
    "lr = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_E():\n",
    "    for i in range(e1.size()[1]):\n",
    "        for j in range(e1.size()[0]):\n",
    "            e1[j][i] = e1[j][i]*math.exp(-delta/tauz) + P12p[j]*a[i]+P12m[i]*snn.states[0][0][j]  \n",
    "            \n",
    "    for i in range(e2.size()[1]):\n",
    "        for j in range(e2.size()[0]):\n",
    "            e2[j][i] = e2[j][i]*math.exp(-delta/tauz) + P23p[j]*snn.states[0][0][i]+P23m[i]*snn.states[1][0][j]\n",
    "    return e1,e2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output 0.0\n",
      "label 0.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6909,  0.0824],\n",
      "        [ 0.6587, -0.2232],\n",
      "        [ 0.2863,  0.0133],\n",
      "        [ 0.4934, -0.0448],\n",
      "        [ 0.4625,  0.6565]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1993, 0.0339, 0.0000, 0.2545, 0.0000]], requires_grad=True)]\n",
      "output 0.0\n",
      "label 1.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6909,  0.0824],\n",
      "        [ 0.6587, -0.2232],\n",
      "        [ 0.2836,  0.0105],\n",
      "        [ 0.4908, -0.0477],\n",
      "        [ 0.4011,  0.6204]], requires_grad=True), Parameter containing:\n",
      "tensor([[1.9925e-01, 3.3895e-02, 7.5048e-05, 2.5459e-01, 8.4750e-04]],\n",
      "       requires_grad=True)]\n",
      "output 1.0\n",
      "label 1.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.7061,  0.1210],\n",
      "        [ 0.7502, -0.0724],\n",
      "        [ 0.3746,  0.1685],\n",
      "        [ 0.5902,  0.1285],\n",
      "        [ 0.5005,  0.7966]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.2359, 0.0904, 0.0748, 0.3450, 0.0912]], requires_grad=True)]\n",
      "output 1.0\n",
      "label 0.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6798,  0.0968],\n",
      "        [ 0.6600, -0.1558],\n",
      "        [ 0.2634,  0.0736],\n",
      "        [ 0.4790,  0.0336],\n",
      "        [ 0.3893,  0.7017]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.2073, 0.0477, 0.0000, 0.2546, 0.0008]], requires_grad=True)]\n",
      "output 0.0\n",
      "label 0.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6179,  0.0292],\n",
      "        [ 0.5686, -0.0325],\n",
      "        [ 0.0782, -0.0053],\n",
      "        [ 0.0266, -0.3842],\n",
      "        [-1.0000,  0.0165]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1336, 0.1338, 0.0010, 0.0202, 0.0071]], requires_grad=True)]\n",
      "output 0.0\n",
      "label 1.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6179,  0.0292],\n",
      "        [ 0.5686, -0.0325],\n",
      "        [ 0.0782, -0.0053],\n",
      "        [ 0.0266, -0.3842],\n",
      "        [-1.0000,  0.0165]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1336, 0.1338, 0.0010, 0.0202, 0.0071]], requires_grad=True)]\n",
      "output 0.0\n",
      "label 1.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6179,  0.0292],\n",
      "        [ 0.5686, -0.0325],\n",
      "        [ 0.0782, -0.0053],\n",
      "        [ 0.0266, -0.3842],\n",
      "        [-1.0000,  0.0165]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1336, 0.1338, 0.0010, 0.0202, 0.0071]], requires_grad=True)]\n",
      "output 0.0\n",
      "label 0.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6179,  0.0292],\n",
      "        [ 0.5686, -0.0325],\n",
      "        [ 0.0782, -0.0053],\n",
      "        [ 0.0266, -0.3842],\n",
      "        [-1.0000,  0.0165]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1336, 0.1338, 0.0010, 0.0202, 0.0071]], requires_grad=True)]\n",
      "output 0.0\n",
      "label 0.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6179,  0.0292],\n",
      "        [ 0.5686, -0.0325],\n",
      "        [ 0.0782, -0.0053],\n",
      "        [ 0.0242, -0.6513],\n",
      "        [-1.0000,  0.0260]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1336, 0.1338, 0.0010, 0.0202, 0.0071]], requires_grad=True)]\n",
      "output 0.0\n",
      "label 1.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6179,  0.0292],\n",
      "        [ 0.5686, -0.0325],\n",
      "        [ 0.0782, -0.0053],\n",
      "        [ 0.0242, -0.6513],\n",
      "        [-1.0000,  0.0231]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1336, 0.1338, 0.0010, 0.0202, 0.0071]], requires_grad=True)]\n",
      "output 0.0\n",
      "label 1.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6179,  0.0292],\n",
      "        [ 0.5686, -0.0325],\n",
      "        [ 0.0782, -0.0053],\n",
      "        [ 0.0242, -0.6513],\n",
      "        [-1.0000,  0.0231]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1336, 0.1338, 0.0010, 0.0202, 0.0071]], requires_grad=True)]\n",
      "output 0.0\n",
      "label 0.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6179,  0.0292],\n",
      "        [ 0.5686, -0.0325],\n",
      "        [ 0.0782, -0.0053],\n",
      "        [ 0.0242, -0.6513],\n",
      "        [-1.0000,  0.0231]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1336, 0.1338, 0.0010, 0.0202, 0.0071]], requires_grad=True)]\n",
      "output 0.0\n",
      "label 0.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6179,  0.0292],\n",
      "        [ 0.5686, -0.0325],\n",
      "        [ 0.0782, -0.0053],\n",
      "        [ 0.0335, -0.8935],\n",
      "        [-1.0000,  0.0214]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1336, 0.1338, 0.0010, 0.0202, 0.0071]], requires_grad=True)]\n",
      "output 0.0\n",
      "label 1.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6179,  0.0292],\n",
      "        [ 0.5686, -0.0325],\n",
      "        [ 0.0782, -0.0053],\n",
      "        [ 0.0335, -0.8935],\n",
      "        [-1.0000,  0.0214]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1336, 0.1338, 0.0010, 0.0202, 0.0071]], requires_grad=True)]\n",
      "output 0.0\n",
      "label 1.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6179,  0.0292],\n",
      "        [ 0.5686, -0.0325],\n",
      "        [ 0.0782, -0.0053],\n",
      "        [ 0.0277, -0.9116],\n",
      "        [-1.0000,  0.0214]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1336, 0.1338, 0.0010, 0.0202, 0.0071]], requires_grad=True)]\n",
      "output 0.0\n",
      "label 0.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6179,  0.0292],\n",
      "        [ 0.5686, -0.0325],\n",
      "        [ 0.0782, -0.0053],\n",
      "        [ 0.0277, -0.9116],\n",
      "        [-1.0000,  0.0214]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1336, 0.1338, 0.0010, 0.0202, 0.0071]], requires_grad=True)]\n",
      "output 0.0\n",
      "label 0.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6179,  0.0292],\n",
      "        [ 0.5686, -0.0325],\n",
      "        [ 0.0782, -0.0053],\n",
      "        [ 0.0269, -1.0000],\n",
      "        [-1.0000,  0.0191]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1336, 0.1338, 0.0010, 0.0202, 0.0071]], requires_grad=True)]\n",
      "output 0.0\n",
      "label 1.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6179,  0.0292],\n",
      "        [ 0.5686, -0.0325],\n",
      "        [ 0.0782, -0.0053],\n",
      "        [ 0.0269, -1.0000],\n",
      "        [-1.0000,  0.0191]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1336, 0.1338, 0.0010, 0.0202, 0.0071]], requires_grad=True)]\n",
      "output 0.0\n",
      "label 1.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6179,  0.0292],\n",
      "        [ 0.5686, -0.0325],\n",
      "        [ 0.0782, -0.0053],\n",
      "        [ 0.0269, -1.0000],\n",
      "        [-1.0000,  0.0191]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1336, 0.1338, 0.0010, 0.0202, 0.0071]], requires_grad=True)]\n",
      "output 0.0\n",
      "label 0.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6179,  0.0292],\n",
      "        [ 0.5686, -0.0325],\n",
      "        [ 0.0782, -0.0053],\n",
      "        [ 0.0269, -1.0000],\n",
      "        [-1.0000,  0.0191]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1336, 0.1338, 0.0010, 0.0202, 0.0071]], requires_grad=True)]\n",
      "output 0.0\n",
      "label 0.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6179,  0.0292],\n",
      "        [ 0.5686, -0.0325],\n",
      "        [ 0.0782, -0.0053],\n",
      "        [ 0.0269, -1.0000],\n",
      "        [-1.0000,  0.0215]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1336, 0.1338, 0.0010, 0.0202, 0.0071]], requires_grad=True)]\n",
      "output 0.0\n",
      "label 1.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6179,  0.0292],\n",
      "        [ 0.5686, -0.0325],\n",
      "        [ 0.0782, -0.0053],\n",
      "        [ 0.0269, -1.0000],\n",
      "        [-1.0000,  0.0215]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1336, 0.1338, 0.0010, 0.0202, 0.0071]], requires_grad=True)]\n",
      "output 0.0\n",
      "label 1.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6179,  0.0292],\n",
      "        [ 0.5686, -0.0325],\n",
      "        [ 0.0782, -0.0053],\n",
      "        [ 0.0269, -1.0000],\n",
      "        [-1.0000,  0.0215]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1336, 0.1338, 0.0010, 0.0202, 0.0071]], requires_grad=True)]\n",
      "output 0.0\n",
      "label 0.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6179,  0.0292],\n",
      "        [ 0.5686, -0.0325],\n",
      "        [ 0.0782, -0.0053],\n",
      "        [ 0.0269, -1.0000],\n",
      "        [-1.0000,  0.0215]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1336, 0.1338, 0.0010, 0.0202, 0.0071]], requires_grad=True)]\n",
      "output 0.0\n",
      "label 0.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6179,  0.0292],\n",
      "        [ 0.5686, -0.0325],\n",
      "        [ 0.0782, -0.0053],\n",
      "        [ 0.0368, -1.0000],\n",
      "        [-1.0000,  0.0241]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1336, 0.1338, 0.0010, 0.0202, 0.0071]], requires_grad=True)]\n",
      "output 0.0\n",
      "label 1.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6179,  0.0292],\n",
      "        [ 0.5686, -0.0325],\n",
      "        [ 0.0782, -0.0053],\n",
      "        [ 0.0368, -1.0000],\n",
      "        [-1.0000,  0.0241]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1336, 0.1338, 0.0010, 0.0202, 0.0071]], requires_grad=True)]\n",
      "output 0.0\n",
      "label 1.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6179,  0.0292],\n",
      "        [ 0.5686, -0.0325],\n",
      "        [ 0.0782, -0.0053],\n",
      "        [ 0.0337, -1.0000],\n",
      "        [-1.0000,  0.0241]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1336, 0.1338, 0.0010, 0.0202, 0.0071]], requires_grad=True)]\n",
      "output 0.0\n",
      "label 0.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6179,  0.0292],\n",
      "        [ 0.5686, -0.0325],\n",
      "        [ 0.0782, -0.0053],\n",
      "        [ 0.0337, -1.0000],\n",
      "        [-1.0000,  0.0241]], requires_grad=True), Parameter containing:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1336, 0.1338, 0.0010, 0.0202, 0.0071]], requires_grad=True)]\n",
      "output 0.0\n",
      "label 0.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6179,  0.0292],\n",
      "        [ 0.5686, -0.0325],\n",
      "        [ 0.0782, -0.0053],\n",
      "        [ 0.0266, -1.0000],\n",
      "        [-1.0000,  0.0204]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1336, 0.1338, 0.0010, 0.0202, 0.0071]], requires_grad=True)]\n",
      "output 0.0\n",
      "label 1.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6179,  0.0292],\n",
      "        [ 0.5686, -0.0325],\n",
      "        [ 0.0782, -0.0053],\n",
      "        [ 0.0266, -1.0000],\n",
      "        [-1.0000,  0.0204]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1336, 0.1338, 0.0010, 0.0202, 0.0071]], requires_grad=True)]\n",
      "output 0.0\n",
      "label 1.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6179,  0.0292],\n",
      "        [ 0.5686, -0.0325],\n",
      "        [ 0.0782, -0.0053],\n",
      "        [ 0.0293, -1.0000],\n",
      "        [-1.0000,  0.0204]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1336, 0.1338, 0.0010, 0.0202, 0.0071]], requires_grad=True)]\n",
      "output 0.0\n",
      "label 0.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6179,  0.0292],\n",
      "        [ 0.5686, -0.0325],\n",
      "        [ 0.0782, -0.0053],\n",
      "        [ 0.0293, -1.0000],\n",
      "        [-1.0000,  0.0204]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1336, 0.1338, 0.0010, 0.0202, 0.0071]], requires_grad=True)]\n",
      "output 0.0\n",
      "label 0.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6179,  0.0292],\n",
      "        [ 0.5686, -0.0325],\n",
      "        [ 0.0782, -0.0053],\n",
      "        [ 0.0219, -1.0000],\n",
      "        [-1.0000,  0.0216]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1336, 0.1338, 0.0010, 0.0202, 0.0071]], requires_grad=True)]\n",
      "output 0.0\n",
      "label 1.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6179,  0.0292],\n",
      "        [ 0.5686, -0.0325],\n",
      "        [ 0.0782, -0.0053],\n",
      "        [ 0.0219, -1.0000],\n",
      "        [-1.0000,  0.0216]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1336, 0.1338, 0.0010, 0.0202, 0.0071]], requires_grad=True)]\n",
      "output 0.0\n",
      "label 1.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6179,  0.0292],\n",
      "        [ 0.5686, -0.0325],\n",
      "        [ 0.0782, -0.0053],\n",
      "        [ 0.0219, -1.0000],\n",
      "        [-1.0000,  0.0216]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1336, 0.1338, 0.0010, 0.0202, 0.0071]], requires_grad=True)]\n",
      "output 0.0\n",
      "label 0.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6179,  0.0292],\n",
      "        [ 0.5686, -0.0325],\n",
      "        [ 0.0782, -0.0053],\n",
      "        [ 0.0219, -1.0000],\n",
      "        [-1.0000,  0.0216]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1336, 0.1338, 0.0010, 0.0202, 0.0071]], requires_grad=True)]\n",
      "output 0.0\n",
      "label 0.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6179,  0.0292],\n",
      "        [ 0.5686, -0.0325],\n",
      "        [ 0.0782, -0.0053],\n",
      "        [ 0.0219, -1.0000],\n",
      "        [-1.0000,  0.0184]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1336, 0.1338, 0.0010, 0.0202, 0.0071]], requires_grad=True)]\n",
      "output 0.0\n",
      "label 1.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6179,  0.0292],\n",
      "        [ 0.5686, -0.0325],\n",
      "        [ 0.0782, -0.0053],\n",
      "        [ 0.0219, -1.0000],\n",
      "        [-1.0000,  0.0184]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1336, 0.1338, 0.0010, 0.0202, 0.0071]], requires_grad=True)]\n",
      "output 0.0\n",
      "label 1.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6179,  0.0292],\n",
      "        [ 0.5686, -0.0325],\n",
      "        [ 0.0782, -0.0053],\n",
      "        [ 0.0219, -1.0000],\n",
      "        [-1.0000,  0.0184]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1336, 0.1338, 0.0010, 0.0202, 0.0071]], requires_grad=True)]\n",
      "output 0.0\n",
      "label 0.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.6179,  0.0292],\n",
      "        [ 0.5686, -0.0325],\n",
      "        [ 0.0782, -0.0053],\n",
      "        [ 0.0219, -1.0000],\n",
      "        [-1.0000,  0.0184]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1336, 0.1338, 0.0010, 0.0202, 0.0071]], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    #print(i)\n",
    "    for d in range(len(x)):\n",
    "        inp_spike = encoding(x[d])\n",
    "        P12p = 0\n",
    "        P12m = 0\n",
    "        P23p = 0\n",
    "        P23m = 0\n",
    "        e1 = torch.zeros_like(list(snn.parameters())[0])\n",
    "        e2 = torch.zeros_like(list(snn.parameters())[1])\n",
    "        snn.reset()\n",
    "        #print(list(snn.parameters()))\n",
    "        for t in range(T):\n",
    "            out = snn(inp_spike[...,t])\n",
    "            #print(out.item())\n",
    "            R = reward(out.item(),y[d].item())\n",
    "            P12p = P12p*math.exp(-delta/taup)+Ap*snn.states[0][0]\n",
    "            P12m = P12m*math.exp(-delta/taum)+Am*inp_spike[...,t]\n",
    "            P23p = P23p*math.exp(-delta/taup)+Ap*snn.states[1][0]\n",
    "            P23m = P23m*math.exp(-delta/taum)+Am*snn.states[0][0]\n",
    "            e1,e2 = update_E()\n",
    "        #print(e1,e2)\n",
    "            R = reward(out.item(),y[d].item())\n",
    "            for idx,w in enumerate(snn.parameters()):\n",
    "                if idx == 0:\n",
    "                    w.data = w.data + lr*R*e1\n",
    "                    w.data = torch.clamp(w.data,-1,1)\n",
    "                else:\n",
    "                    w.data = w.data + lr*R*e2\n",
    "                    w.data = torch.clamp(w.data,0,1)\n",
    "        if i%100 == 0:\n",
    "            print('output',out.item())\n",
    "            print('label',y[d].item())\n",
    "            print(list(snn.parameters()))\n",
    "            print(e1,e2)\n",
    "        \n",
    "    #print(i)\n",
    "    #print(e1,e2)\n",
    "    #print(P12p,P12m,P23p,P23m)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hebbian Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0.0006, 0.0006],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0001, 0.0001],\n",
      "        [0.0000, 0.0000]], grad_fn=<CopySlices>), tensor([[2.8000e-04, 0.0000e+00, 0.0000e+00, 7.0000e-05, 0.0000e+00]],\n",
      "       grad_fn=<CopySlices>))\n"
     ]
    }
   ],
   "source": [
    "def update_weight_Hebb(trace1,trace2,trace3):\n",
    "    w1 = torch.zeros_like(list(snn.parameters())[0])\n",
    "    for i in range(w1.size()[1]):\n",
    "        for j in range(w1.size()[0]):\n",
    "            w1[j][i] = alpha*trace2[j]*trace1[i]            \n",
    "\n",
    "    w2 = torch.zeros_like(list(snn.parameters())[1])\n",
    "    for i in range(w2.size()[1]):\n",
    "        for j in range(w2.size()[0]):\n",
    "            w2[j][i] = alpha*trace3[j]*trace2[i]\n",
    "    return w1,w2 \n",
    "#print(update_weight_STDP(trace1,trace2,trace3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "100\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "200\n",
      "[0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "n_iter = 201\n",
    "decay = 0.002\n",
    "alpha = 0.175\n",
    "\n",
    "for i in range(n_iter):\n",
    "    output = []\n",
    "    for inp in x:\n",
    "        inp_spike = encoding(inp)\n",
    "        trace1 = 0\n",
    "        trace2 = 0\n",
    "        trace3 = 0\n",
    "        snn.reset()\n",
    "        for t in range(T):\n",
    "            out = snn(inp_spike[...,t])\n",
    "            trace1 += inp_spike[...,t]\n",
    "            trace2 += snn.states[0][0]\n",
    "            trace3 += snn.states[1][0]\n",
    "        output.append(out.item())\n",
    "        trace1 = trace1/T\n",
    "        trace2 = trace2/T\n",
    "        trace3 = trace3/T\n",
    "        w1,w2 = update_weight_Hebb(trace1, trace2, trace3)\n",
    "        for idx,w in enumerate(snn.parameters()):\n",
    "            if idx == 0:\n",
    "                w.data = w1 + w.data*(1-decay)\n",
    "            else:\n",
    "                w.data = w2 + w.data*(1-decay)\n",
    "    if i%100 == 0:\n",
    "        print(i)\n",
    "        print(output)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 0.4554, -0.2323],\n",
      "        [-0.7028, -0.2477],\n",
      "        [-0.4719, -0.0389],\n",
      "        [-0.3774,  0.6311],\n",
      "        [ 0.0950,  0.0724]], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.3258,  0.0890,  0.3129, -0.1612, -0.2478]], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(snn.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]], grad_fn=<CopySlices>) tensor([[0., 0., 0., 0., 0.]], grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "print(e1,e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4800)\n"
     ]
    }
   ],
   "source": [
    "y_hat = (count>5).float()\n",
    "y_hat = y_hat.squeeze(-1)\n",
    "criterion = torch.nn.MSELoss()\n",
    "loss = criterion(y_hat.resize(50),y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1.])\n",
      "tensor(0., grad_fn=<SelectBackward>)\n",
      "tensor([0., 1.])\n"
     ]
    }
   ],
   "source": [
    "print(x[0])\n",
    "snna = SpikingMLP(sizes)\n",
    "out = snna(x[0])\n",
    "print(snna.states[0][0][0])\n",
    "print(test[0][...,1])#[0:2,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
