{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9FgrWIgiaqcs"
   },
   "outputs": [],
   "source": [
    "#Mounting content from Google Drive\n",
    "#from google.colab import drive\n",
    "#import os\n",
    "#drive.mount('/content/gdrive')\n",
    "#!ls '/content/gdrive/My Drive/'\n",
    "#path = '/content/gdrive/My Drive/Master Thesis/' #set the path as your own location\n",
    "#os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WmT5TlUVa8FU"
   },
   "outputs": [],
   "source": [
    "from typing import Optional, NamedTuple, Tuple, Any, Sequence\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import datetime\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import heapq\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PmbHRkkyv6vA"
   },
   "outputs": [],
   "source": [
    "class SpikeFunction(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Spiking function with rectangular gradient.\n",
    "    Source: https://www.frontiersin.org/articles/10.3389/fnins.2018.00331/full\n",
    "    Implementation: https://github.com/combra-lab/pop-spiking-deep-rl/blob/main/popsan_drl/popsan_td3/popsan.py\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx: Any, v: torch.Tensor) -> torch.Tensor:\n",
    "        ctx.save_for_backward(v)  # save voltage - thresh for backwards pass\n",
    "        return v.gt(0.0).float()\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx: Any, grad_output: torch.Tensor) -> Tuple[torch.Tensor, ...]:\n",
    "        v, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        spike_pseudo_grad = (v.abs() < 0.5).float()  # 0.5 is the width of the rectangle\n",
    "        return grad_input * spike_pseudo_grad, None  # ensure a tuple is returned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34GWATKai2L2"
   },
   "source": [
    "## Define Hyperparameters and Initialize Parameters to be Evolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "BnuwYPXEix1Z"
   },
   "outputs": [],
   "source": [
    "popu = 30\n",
    "net_size = [7840,256,64]\n",
    "N_neuron = sum(net_size)\n",
    "i_decay_pool = torch.rand(popu,N_neuron)\n",
    "v_decay_pool = torch.rand(popu,N_neuron)\n",
    "thresh_pool = torch.rand(popu,N_neuron)\n",
    "encoder_pool = torch.empty(popu).random_(2) #0: population encoder, 1: position encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "RL8g30sdwExf"
   },
   "outputs": [],
   "source": [
    "class LIFState(NamedTuple):\n",
    "    z: torch.Tensor\n",
    "    v: torch.Tensor\n",
    "    i: torch.Tensor\n",
    "\n",
    "class LIF(nn.Module):\n",
    "    \"\"\"\n",
    "    Leaky-integrate-and-fire neuron with learnable parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size: int, n: int):\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        self.n = n #index of each individual\n",
    "        # Put the neurons parameters to the corresponding layer\n",
    "        if size == net_size[0]:\n",
    "            self.i_decay = nn.Parameter(i_decay_pool[n,0:net_size[0]])\n",
    "            self.v_decay = nn.Parameter(v_decay_pool[n,0:net_size[0]])\n",
    "            self.thresh = nn.Parameter(thresh_pool[n,0:net_size[0]])\n",
    "            self.spike = SpikeFunction.apply  # spike function\n",
    "        if size == net_size[1]:\n",
    "            self.i_decay = nn.Parameter(i_decay_pool[n,net_size[0]:(net_size[0]+net_size[1])])\n",
    "            self.v_decay = nn.Parameter(v_decay_pool[n,net_size[0]:(net_size[0]+net_size[1])])\n",
    "            self.thresh = nn.Parameter(thresh_pool[n,net_size[0]:(net_size[0]+net_size[1])])\n",
    "            self.spike = SpikeFunction.apply  # spike function\n",
    "        if size == net_size[2]:\n",
    "            self.i_decay = nn.Parameter(i_decay_pool[n,(net_size[0]+net_size[1]):N_neuron])\n",
    "            self.v_decay = nn.Parameter(v_decay_pool[n,(net_size[0]+net_size[1]):N_neuron])\n",
    "            self.thresh = nn.Parameter(thresh_pool[n,(net_size[0]+net_size[1]):N_neuron])\n",
    "            self.spike = SpikeFunction.apply  # spike function\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        synapse: nn.Module,\n",
    "        z: torch.Tensor,\n",
    "        state: Optional[LIFState] = None,\n",
    "    ) -> Tuple[torch.Tensor, LIFState]:\n",
    "        # Previous state\n",
    "        if state is None:\n",
    "            state = LIFState(\n",
    "                z=torch.zeros_like(synapse(z)),\n",
    "                v=torch.zeros_like(synapse(z)),\n",
    "                i=torch.zeros_like(synapse(z)),\n",
    "            )\n",
    "        # Update state\n",
    "        i = state.i * self.i_decay + synapse(z)\n",
    "        v = state.v * self.v_decay * (1.0 - state.z) + i\n",
    "        z = self.spike(v - self.thresh)\n",
    "        return z, LIFState(z, v, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "YGD1D7qawG1u"
   },
   "outputs": [],
   "source": [
    "class SpikingMLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Spiking network with LIF neuron model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sizes: Sequence[int], n: Sequence[int]):\n",
    "        super().__init__()\n",
    "        self.sizes = sizes\n",
    "        self.n = n\n",
    "        self.spike = SpikeFunction.apply\n",
    "\n",
    "        # Define layers\n",
    "        self.synapses = nn.ModuleList()\n",
    "        self.neurons = nn.ModuleList()\n",
    "        self.states = []\n",
    "        # Loop over current (accessible with 'size') and next (accessible with 'sizes[i]') element\n",
    "        for i, size in enumerate(sizes[:-1], start=1):\n",
    "            # Parameters of synapses and neurons are randomly initialized\n",
    "            self.synapses.append(nn.Linear(size, sizes[i], bias=False))\n",
    "            self.neurons.append(LIF(sizes[i],n))\n",
    "            self.states.append(None)\n",
    "\n",
    "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        for i, (neuron, synapse) in enumerate(zip(self.neurons, self.synapses)):\n",
    "            z, self.states[i] = neuron(synapse, z, self.states[i])\n",
    "        return z\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resetting states when you're done is very important!\n",
    "        \"\"\"\n",
    "        for i, _ in enumerate(self.states):\n",
    "            self.states[i] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAnkvPAh8ZuM"
   },
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "bDbq5jqX8IM6"
   },
   "outputs": [],
   "source": [
    "def spike_train_encoding(x: torch.Tensor, n: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Encode a tensor of shape (batch, values) into a spike train tensor\n",
    "    with shape (batch, values, n).\n",
    "    \n",
    "    Assumes x is in range [0, 1], denoting the spike probabilities.\n",
    "    \"\"\"\n",
    "    # x: shape (batch, values) -> spikes: shape (batch, values, n)\n",
    "    batch, values = x.shape  #[64, 784]\n",
    "    x = x.unsqueeze(-1)\n",
    "    spikes = torch.rand(batch, values, n, dtype=x.dtype, device=x.device)\n",
    "    return (spikes < x).float() #[64, 784, 10]\n",
    "\n",
    "def spike_population_encoding(x: torch.Tensor, pop: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Encode a tensor of shape (batch, values) into a spike population tensor\n",
    "    with shape (batch, values, pop).\n",
    "    \n",
    "    Assumes x is in range [0, 1], denoting the spike probabilities.\n",
    "    \n",
    "    NOTE: this is the same as spike_train_encoding(), but dimensions\n",
    "    will be treated differently later on!\n",
    "    \"\"\"\n",
    "    batch, values = x.shape\n",
    "    output = torch.reshape(spike_train_encoding(x, pop),(batch,values*pop)) #reshape from [64,784,10] to [64,7840]\n",
    "  \n",
    "    return output #[64, 7840]\n",
    "   \n",
    "\n",
    "\n",
    "def spike_position_encoding(x: torch.Tensor, bins: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    A deterministic position encoding, where we have a certain number of bins\n",
    "    to discretize the continuous input value.\n",
    "    \n",
    "    This is based on the idea of 'place cells'\n",
    "    (https://en.wikipedia.org/wiki/Place_cell). A stochastic variant\n",
    "    of this is also possible, where the bins have the shape of a normal\n",
    "    distribution (radial basis functions) and represent spiking probabilities.\n",
    "    \n",
    "    Assumes x is in range [0, 1].\n",
    "    \"\"\"\n",
    "    # Add bin dimension\n",
    "    batch, values = x.shape\n",
    "    x = x.unsqueeze(-1)\n",
    "    # Get bins of same shape\n",
    "    # Of course, it would be more efficient to create this tensor only once\n",
    "    bins = bins+1 #10 neurons need 11 bins\n",
    "    bins = torch.linspace(0, 1, bins, dtype=x.dtype, device=x.device).view(1, 1, -1).expand(batch, values, -1).clone()\n",
    "    # Get spikes\n",
    "    # See documentation for searchsorted() to see how it works\n",
    "    # Only last dimension of x and bins can be different\n",
    "    spikes = torch.searchsorted(bins, x)  # right-bound inclusive [64,784,1], position of the spike\n",
    "    index_spikes = torch.reshape(spikes,(batch*values,1))-1 #convert position to index of the spiking neuron\n",
    "    index_position = torch.arange(batch*values, device=x.device).reshape(batch*values,1)\n",
    "    output = torch.zeros([batch*values,10],device=x.device) #empty neurons\n",
    "    replace = torch.ones([1],device=x.device)\n",
    "    output.index_put_((index_position,index_spikes),replace) #replace 0 by 1 at the spiking neurons\n",
    "    return torch.reshape(output,(batch,values*10)) #[64, 7840]\n",
    "\n",
    "encoder_list = [spike_population_encoding,spike_position_encoding]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uHtSPH_Q8duJ"
   },
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "gKE95BCz8Yud"
   },
   "outputs": [],
   "source": [
    "class VoltageDecoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Voltage decoder with learnable parameters (hence a class).\n",
    "    \n",
    "    Just acts like a non-leaky integrate-and-fire (IF) neuron.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_size: int, out_size: int):\n",
    "        super().__init__()\n",
    "        # Synapse between network and decoder\n",
    "        self.synapse = nn.Linear(in_size, out_size)\n",
    "        # Learnable voltage decay\n",
    "        self.v_decay = nn.Parameter(torch.rand(out_size))\n",
    "        \n",
    "    def forward(self, z: torch.Tensor, v: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        # Previous v\n",
    "        if v is None:\n",
    "            v = torch.zeros_like(self.synapse(z))\n",
    "        # Update\n",
    "        i = self.synapse(z)\n",
    "        v = v * self.v_decay + i\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ABHxdrWE8ksX"
   },
   "outputs": [],
   "source": [
    " class SpikingClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Classifier SNN that makes use of current encoding and volt decoding\n",
    "    (should have as little loss-of-signal as possible).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,n: int, net_sizes: Sequence[int] = [7840, 256, 64], out_size: int = 10):\n",
    "        super().__init__()\n",
    "        self.n = n\n",
    "        # Encoder\n",
    "        self.encoder = encoder_list[int(encoder_pool[n])] #spike_current_encoding\n",
    "        # Network\n",
    "        self.snn = SpikingMLP(net_sizes,n) #network for each individual\n",
    "        # Decoder\n",
    "        self.decoder = VoltageDecoding(net_sizes[-1], out_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Flatten image\n",
    "        batch, channel, height, width = x.shape\n",
    "        x = x.view(batch, -1)\n",
    "        \n",
    "        # Encode entire sequence\n",
    "        i_in = self.encoder(x,10)\n",
    "        \n",
    "        # Reset network\n",
    "        self.snn.reset()\n",
    "        \n",
    "        # Run: just one step!\n",
    "        # Network\n",
    "        z = self.snn(i_in)\n",
    "        # Decoder\n",
    "        v_out = self.decoder(z)\n",
    "        \n",
    "        return v_out  #v_out.shape = [64,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "yzDP8dY38wXo"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "def train(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    optimizer: optim.Optimizer,\n",
    "    device: torch.device,\n",
    "    epoch: int,\n",
    "    log_interval: int = 64,\n",
    "):\n",
    "    # Set to train mode\n",
    "    model.train()\n",
    "    \n",
    "    # Do one epoch\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # Move to GPU (if applicable)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Predict\n",
    "        output = model(data)\n",
    "        # Get loss\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        # Do backprop\n",
    "        loss.backward()\n",
    "        # Learn\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Log\n",
    "        #if batch_idx % log_interval == 0:\n",
    "            #print(f\"train epoch: {epoch} [{batch_idx}/{len(train_loader)}]\\tloss: {loss.item():.6f}\")\n",
    "            \n",
    "\n",
    "def test(model: nn.Module, test_loader: DataLoader, device: torch.device):\n",
    "    # Set to test/eval mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Counters\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    # Don't update graph\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            # Move to GPU\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # Predict\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction=\"sum\").item()\n",
    "            # See if correct\n",
    "            pred = output.argmax(1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100.0 * correct / len(test_loader.dataset)\n",
    "    #print(f\"\\ntest: avg loss: {test_loss:.4f}, accuracy: {accuracy:.1f}%\\n\")\n",
    "    \n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "5XvCVuDimIId"
   },
   "outputs": [],
   "source": [
    "def breed(min_loss, par1, par2, par3, par4):\n",
    "    '''Select individuls with smaller loss, par1, par2, par3 are neuron \n",
    "    parameter, par4 is the index of encoder'''    \n",
    "    half_popu = int(popu/2)\n",
    "    good_index = heapq.nsmallest(half_popu, range(len(min_loss)), min_loss.__getitem__)\n",
    "    parents1 = par1[good_index]  \n",
    "    parents2 = par2[good_index]\n",
    "    parents3 = par3[good_index]\n",
    "    parents4 = par4[good_index]\n",
    "    mu_neuron = torch.rand_like(parents1)+0.5 #parameters vary in the range of [50%,150%]\n",
    "    mu_encoder = torch.cat([torch.zeros(int(0.4*popu)),torch.ones(int(0.1*popu))],0) #20% possibility of mutation\n",
    "    mu_encoder = mu_encoder[torch.randperm(mu_encoder.size()[0])]\n",
    "    new_par1 = torch.cat((parents1,parents1*mu_neuron),0)\n",
    "    new_par2 = torch.cat((parents2,parents2*mu_neuron),0)\n",
    "    new_par3 = torch.cat((parents3,parents3*mu_neuron),0)\n",
    "    new_par4 = torch.cat((parents4,abs(mu_encoder-parents4)),0)\n",
    "    return new_par1,new_par2,new_par3,new_par4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HZxgZ3R682OB",
    "outputId": "d7e241d9-c39a-446e-815d-40290a0b2f78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[0.20289878854751586, 0.20316954841017723, 0.20420764437317848, 0.20534762805700302, 0.20565676441788674, 0.20794454568624496, 0.20833383709788322, 0.2113780371785164, 0.21180731242895126, 0.22232588243484497, 0.22723007258176803, 0.22791901705265044, 0.23515106321573256, 0.23961178255081178, 0.2555751905143261, 0.6953482852935791, 0.703564900970459, 0.7802230184555053, 0.7822952578544616, 0.8113776509284973, 0.8411556464195251, 0.8504612324714661, 0.866305062007904, 0.8702998962402344, 0.8789214824676513, 0.9339030861854554, 0.9376825727462769, 0.9998296499252319, 1.060860987472534, 1.1112602071762085]\n",
      "1\n",
      "[0.1913862202525139, 0.20168669731020927, 0.2044870375931263, 0.20738442553281783, 0.20755948738455773, 0.20846164550185203, 0.20899792821407318, 0.20936037682890893, 0.20948406853079796, 0.20950489243268966, 0.20984686757326126, 0.2099250315248966, 0.2104313025712967, 0.21255700039863587, 0.21387489842176438, 0.21466880445480346, 0.21509594742059707, 0.21616980971693991, 0.21689910821914674, 0.21925629643201827, 0.21956638841629028, 0.22251677697896957, 0.2225361404299736, 0.22261812250614166, 0.2248172540307045, 0.22555980206727982, 0.22845592688322067, 0.6920620053291321, 1.0483840133666993, 1.0890216526031493]\n",
      "2\n",
      "[0.19903252363801002, 0.1992378263771534, 0.19941836262345314, 0.20113635258674623, 0.20166990975141524, 0.20218302860856055, 0.20294083379507064, 0.20564839214086533, 0.20722206807136537, 0.20819871791005135, 0.21190199699401854, 0.213706644654274, 0.2145110033273697, 0.21573876231908798, 0.21629900909662247, 0.21646433016061783, 0.21777820264101028, 0.21847454985380171, 0.21901856713294984, 0.22321570756435394, 0.2249224284529686, 0.23019048081338406, 0.2313658187031746, 0.23167148048877717, 0.231940094101429, 0.23838516490757466, 0.24045676412582398, 0.8010261739730835, 0.945405892944336, 1.0636570276260375]\n",
      "3\n",
      "[0.1970047110080719, 0.197943562912941, 0.2019346635520458, 0.20369133182764054, 0.20415024468898774, 0.20478191279768942, 0.20538831666111945, 0.20608585422039033, 0.2075894819378853, 0.20861974592208862, 0.20965001872777939, 0.21072745487689973, 0.21318574865460396, 0.21365703917145729, 0.21503604708909987, 0.2167246219277382, 0.21736075996756554, 0.21828355224132537, 0.21877582058906556, 0.22033362005352974, 0.22039672273397445, 0.22145106394290925, 0.22273477753400803, 0.22315000229477883, 0.23086374591588973, 0.2370570784687996, 0.2408428637981415, 0.7626516563415527, 0.7779795108795166, 1.4023470600128174]\n",
      "4\n",
      "[0.20046521846652032, 0.20214212000966073, 0.20327120294570922, 0.2049521086871624, 0.2054959629148245, 0.2084756165444851, 0.21058046402931213, 0.21075098507404327, 0.21129015556573869, 0.21337520079612732, 0.2148125726699829, 0.21647216268777847, 0.2167952176451683, 0.21740002044439316, 0.21786806503534317, 0.21901618753373622, 0.219598732316494, 0.22131463700532913, 0.22212290984392166, 0.22232626447677611, 0.2232035639643669, 0.2238376569032669, 0.2246586617708206, 0.22579598004817963, 0.22640059353113173, 0.2277560735821724, 0.24356669659614563, 0.798963376712799, 0.9085194789886475, 1.083787741279602]\n"
     ]
    }
   ],
   "source": [
    "# Data \n",
    "'''For Local Jupyter Notebook'''\n",
    "mnist_train = MNIST(\".\", train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_test = MNIST(\".\", train=False, download=True, transform=transforms.ToTensor())\n",
    "'''For Google Colab'''\n",
    "#data_path = path + 'data/'\n",
    "#save_path = path + 'model/'\n",
    "#mnist_train = datasets.MNIST(data_path, train = True, download = False, transform = transforms.ToTensor())\n",
    "#mnist_test = datasets.MNIST(data_path, train = False, download = False, transform = transforms.ToTensor())\n",
    "\n",
    "# Dataloaders: 2x as many workers as cores, pin_memory to True\n",
    "train_loader = DataLoader(mnist_train, batch_size=64, shuffle=True, num_workers=32, pin_memory=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=64, shuffle=False, num_workers=32, pin_memory=True)\n",
    "\n",
    "# Check for GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "def generation():\n",
    "    min_loss = []\n",
    "    for i in range(popu):\n",
    "        #print(i)\n",
    "        # Select classifier\n",
    "        classifier = SpikingClassifier(i).to(device)\n",
    "        # Optimizer\n",
    "        optimizer = optim.Adam(classifier.parameters())\n",
    "        # Logging\n",
    "        test_losses = []\n",
    "        test_accs = []\n",
    "        # Run epoch\n",
    "        for e in range(2):\n",
    "            # Train\n",
    "            train(classifier, train_loader, optimizer, device, e)\n",
    "            # Test/validate\n",
    "            test_loss, test_acc = test(classifier, test_loader, device)\n",
    "            # Log\n",
    "            test_losses.append(test_loss)\n",
    "            test_accs.append(test_acc)\n",
    "        min_loss.append(min(test_losses))   \n",
    "    return min_loss\n",
    "\n",
    "N = 5\n",
    "for a in range(N):\n",
    "    print(a)\n",
    "    min_loss = generation()\n",
    "    new_i_decay,new_v_decay,new_thresh,new_encoder = breed(min_loss, i_decay_pool, v_decay_pool, thresh_pool, encoder_pool)\n",
    "    i_decay_pool = new_i_decay\n",
    "    v_decay_pool = new_v_decay\n",
    "    thresh_pool = new_thresh\n",
    "    encoder_pool = new_encoder\n",
    "    print(heapq.nsmallest(popu,min_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2iycoR0e9RGk"
   },
   "source": [
    "## ======================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Evolve_snn_mnist.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
