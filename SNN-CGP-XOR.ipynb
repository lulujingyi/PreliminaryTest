{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, NamedTuple, Tuple, Any, Sequence\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import heapq\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spiking network with the LIF neuron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikeFunction(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Spiking function with rectangular gradient.\n",
    "    Source: https://www.frontiersin.org/articles/10.3389/fnins.2018.00331/full\n",
    "    Implementation: https://github.com/combra-lab/pop-spiking-deep-rl/blob/main/popsan_drl/popsan_td3/popsan.py\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx: Any, v: torch.Tensor) -> torch.Tensor:\n",
    "        ctx.save_for_backward(v)  # save voltage - thresh for backwards pass\n",
    "        return v.gt(0.0).float()\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx: Any, grad_output: torch.Tensor) -> Tuple[torch.Tensor, ...]:\n",
    "        v, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        spike_pseudo_grad = (v.abs() < 0.5).float()  # 0.5 is the width of the rectangle\n",
    "        return grad_input * spike_pseudo_grad, None  # ensure a tuple is returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for LIF state\n",
    "class LIFState(NamedTuple):\n",
    "    z: torch.Tensor\n",
    "    v: torch.Tensor\n",
    "    i: torch.Tensor\n",
    "\n",
    "class LIF(nn.Module):\n",
    "    \"\"\"\n",
    "    Leaky-integrate-and-fire neuron with learnable parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size: int):\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        # Initialize all parameters randomly as U(0, 1)\n",
    "        self.i_decay = torch.rand(size) #self.i_decay = nn.Parameter(torch.rand(size))\n",
    "        self.v_decay = torch.rand(size)\n",
    "        self.thresh = torch.rand(size)\n",
    "        self.spike = SpikeFunction.apply  # spike function\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        synapse: nn.Module,\n",
    "        z: torch.Tensor,\n",
    "        state: Optional[LIFState] = None,\n",
    "    ) -> Tuple[torch.Tensor, LIFState]:\n",
    "        # Previous state\n",
    "        if state is None:\n",
    "            state = LIFState(\n",
    "                z=torch.zeros_like(synapse(z)),\n",
    "                v=torch.zeros_like(synapse(z)),\n",
    "                i=torch.zeros_like(synapse(z)),\n",
    "            )\n",
    "        # Update state\n",
    "        i = state.i * self.i_decay + synapse(z)\n",
    "        #print(self.i_decay)\n",
    "        #print(synapse(z))\n",
    "        v = state.v * self.v_decay * (1.0 - state.z) + i\n",
    "        z = self.spike(v - self.thresh)\n",
    "\n",
    "        return z, LIFState(z, v, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingMLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Spiking network with LIF neuron model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sizes: Sequence[int]):\n",
    "        super().__init__()\n",
    "        self.sizes = sizes\n",
    "        self.spike = SpikeFunction.apply\n",
    "\n",
    "        # Define layers\n",
    "        self.synapses = nn.ModuleList()\n",
    "        self.neurons = nn.ModuleList()\n",
    "        self.states = []\n",
    "        # Loop over current (accessible with 'size') and next (accessible with 'sizes[i]') element\n",
    "        for i, size in enumerate(sizes[:-1], start=1):\n",
    "            # Parameters of synapses and neurons are randomly initialized\n",
    "            self.synapses.append(nn.Linear(size, sizes[i], bias=False))\n",
    "            self.neurons.append(LIF(sizes[i]))\n",
    "            self.states.append(None)\n",
    "           \n",
    "\n",
    "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        for i, (neuron, synapse) in enumerate(zip(self.neurons, self.synapses)):\n",
    "            z, self.states[i] = neuron(synapse, z, self.states[i])\n",
    "        return z\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resetting states when you're done is very important!\n",
    "        \"\"\"\n",
    "        for i, _ in enumerate(self.states):\n",
    "            self.states[i] = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([1., 0., 0., 1., 0., 1., 0., 1., 0., 1.])\n",
      "Class imbalance: 0.5040000081062317\n"
     ]
    }
   ],
   "source": [
    "# Data and labels\n",
    "samples = 1000 #10000\n",
    "x = torch.randint(2, (samples, 2)).float()\n",
    "y = (x.sum(-1) == 1).float()\n",
    "print(x[:10])\n",
    "print(y[:10])\n",
    "print(f\"Class imbalance: {y.sum() / y.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CGP\n",
    "Operands: one presynaptic trace, one postsynaptic trace, reward (1/(loss+0.01))\n",
    "\n",
    "Operators: + - * (/ is excluded for now to avoid invalid learning rules becasue there is no validity check program yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(x,y):\n",
    "        return x+y\n",
    "\n",
    "def sub(x,y):\n",
    "        return x-y\n",
    "\n",
    "def mul(x,y):\n",
    "        return x*y\n",
    "\n",
    "def div(x,y):\n",
    "        return x/y\n",
    "\n",
    "F = [add, sub, mul]#, div]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This very simple index graph has 8 internal nodes: 2 columns, 4 rows. Each internal nodes has a index with three integers. The first integer indicates the operator and second and third integers indicate the inputs. Inputs for internal nodes in the first column are the operands, while inputs for internal nodes in the second column are the outpus of the first comlumn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_operand = 3 #number of operands\n",
    "n_row = 4 #number of rows\n",
    "n_column = 2 #number of columns of internal nodes\n",
    "n_F = len(F) #number of operators\n",
    "\n",
    "def create_node():\n",
    "        internal1 = torch.cat((torch.randint(n_F,(n_row,1)),torch.randint(n_operand,(n_row,n_column))),1)\n",
    "        internal2 = torch.cat((torch.randint(n_F,(n_row,1)),torch.randint(n_row,(n_row,n_column))),1)\n",
    "        internal = torch.cat((internal1,internal2))\n",
    "        return internal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute(S,operand):\n",
    "        pheno = S[0]\n",
    "        i = S[1]\n",
    "        def compute1(i):\n",
    "                operator = F[pheno[i][0]]\n",
    "                output = operator(operand[pheno[i][1]],operand[pheno[i][2]])\n",
    "                return output\n",
    "        if i < n_row:\n",
    "                output = compute1(i)\n",
    "        else:\n",
    "                operator = F[pheno[i][0]]\n",
    "                output = operator(compute1(pheno[i][1]), compute1(pheno[i][2]))\n",
    "        return output\n",
    "\n",
    "def mutation(S):\n",
    "        mu = torch.randn((8,3))#*0.3\n",
    "        #mu = torch.clamp(mu, -1, 1) + 1\n",
    "        mutated_internal = torch.round(S[0]+mu)\n",
    "        l1 = torch.FloatTensor([[0, 0, 0]])\n",
    "        u1 = torch.FloatTensor([[n_F-1, n_operand-1, n_operand-1]]) #[2,2,2]\n",
    "        mutated_internal[:4] = torch.max(torch.min(mutated_internal[:4], u1), l1) #clamp the nodes in the first column within the range [l1, u1]\n",
    "        l2 = torch.FloatTensor([[0, 0, 0]])\n",
    "        u2 = torch.FloatTensor([[n_F-1, n_row-1, n_row-1]]) #[2,3,3] \n",
    "        mutated_internal[4:] = torch.max(torch.min(mutated_internal[4:], u2), l2) #clamp the nodes in the second column within the range [l2, u2]\n",
    "        mutated_internal = mutated_internal.int()\n",
    "        mutated_node_index = torch.randint(len(mutated_internal),(1,1)).item()\n",
    "        mutated_S = [mutated_internal,mutated_node_index]\n",
    "        return mutated_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weight(S,snn,trace1,trace2,trace3,loss):\n",
    "    w1 = torch.zeros_like(list(snn.parameters())[0])\n",
    "    for i in range(w1.size()[1]):\n",
    "        for j in range(w1.size()[0]):\n",
    "            w1[j][i] = compute(S,[trace1[i],trace2[j],loss])\n",
    "\n",
    "    w2 = torch.zeros_like(list(snn.parameters())[1])\n",
    "    for i in range(w2.size()[1]):\n",
    "        for j in range(w2.size()[0]):\n",
    "            w2[j][i] = compute(S,[trace2[i],trace3[j],loss])\n",
    "    return w1,w2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 50\n",
    "epochs = 3\n",
    "decay = 0.5\n",
    "alpha = 1\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "def train(S,snn):\n",
    "    for e in range(epochs):\n",
    "        losses = []\n",
    "        for i in range(samples // batch):\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            #for p in snn.parameters():\n",
    "                #p.grad = None\n",
    "            \n",
    "            # Reset the network\n",
    "            snn.reset()\n",
    "\n",
    "            \n",
    "            trace1 = 0\n",
    "            trace2 = 0\n",
    "            trace3 = 0\n",
    "            prediction = torch.Tensor()\n",
    "            \n",
    "            #traces are computed in a timestep equal to the \n",
    "            for d in range(i*batch,(i+1)*batch): \n",
    "                y_hat = snn(x[d])\n",
    "                prediction = torch.cat((prediction,y_hat))\n",
    "                trace1 = trace1 * decay + alpha * x[d]\n",
    "                trace2 = trace2 * decay + alpha * snn.states[0][0]\n",
    "                trace3 = trace3 * decay + alpha * snn.states[1][0]\n",
    "            loss = criterion(prediction, y[i*batch:(i+1)*batch])    \n",
    "            w1,w2 = update_weight(S,snn, trace1, trace2, trace3, (1/(loss.item()+0.01)))\n",
    "            for i,w in enumerate(snn.parameters()):\n",
    "                    if i == 0:\n",
    "                        w.data = w1 + w.data\n",
    "                    else:\n",
    "                        w.data = w2 + w.data\n",
    "\n",
    "            # Print statistics\n",
    "            losses.append(loss.item())\n",
    "            #print(f\"[{e + 1}, {i}] loss: {loss.item()}\")\n",
    "    return sum(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 + 4 Evolutionary Strategy: 2 random individuals are intialized randomly and thier losses are computed. For each individual, two offsprings are generated by mutation. If the performane of the offspring is better, the offspring will replace the parent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal1 = create_node()\n",
    "\n",
    "node_index1 = torch.randint(len(internal1),(1,1)).item()\n",
    "\n",
    "S1 = [internal1,node_index1]\n",
    "\n",
    "internal2 = create_node()\n",
    "\n",
    "node_index2 = torch.randint(len(internal2),(1,1)).item()\n",
    "\n",
    "S2 = [internal2,node_index2]\n",
    "\n",
    "Stab = [S1,S2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.819999933242798\n"
     ]
    }
   ],
   "source": [
    "sizes = [2,5,1]\n",
    "print(train(S1,SpikingMLP(sizes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.819999933242798, 9.819999933242798]\n"
     ]
    }
   ],
   "source": [
    "L1 = train(S1,SpikingMLP(sizes))\n",
    "L2 = train(S2,SpikingMLP(sizes))\n",
    "Ltab = [L1,L2]\n",
    "print(Ltab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.819999933242798, 9.819999933242798, 9.819999933242798, 10.0799999833107, 9.840000063180923, 9.819999933242798]\n",
      "[9.819999933242798, 9.819999933242798]\n",
      "[7.000000014901161, 9.059999942779541, 9.819999933242798, 9.819999933242798, 10.0799999833107, 9.819999933242798]\n",
      "[7.000000014901161, 9.059999942779541]\n",
      "[7.000000014901161, 9.059999942779541, 10.0799999833107, 9.819999933242798, 9.819999933242798, 9.819999933242798]\n",
      "[7.000000014901161, 9.059999942779541]\n",
      "[7.000000014901161, 9.059999942779541, 9.819999933242798, 9.819999933242798, 9.139999955892563, 10.0799999833107]\n",
      "[7.000000014901161, 9.059999942779541]\n",
      "[7.000000014901161, 9.059999942779541, 10.0799999833107, 9.819999933242798, 10.0799999833107, 9.819999933242798]\n",
      "[7.000000014901161, 9.059999942779541]\n",
      "[7.000000014901161, 9.059999942779541, 10.0799999833107, 10.46000000834465, 9.819999933242798, 9.819999933242798]\n",
      "[7.000000014901161, 9.059999942779541]\n",
      "[7.000000014901161, 8.499999970197678, 9.819999933242798, 9.819999933242798, 10.0799999833107, 9.819999933242798]\n",
      "[7.000000014901161, 8.499999970197678]\n",
      "[7.000000014901161, 8.499999970197678, 9.819999933242798, 9.819999933242798, 9.819999933242798, 10.0799999833107]\n",
      "[7.000000014901161, 8.499999970197678]\n",
      "[7.000000014901161, 8.499999970197678, 9.819999933242798, 10.0799999833107, 9.819999933242798, 10.0799999833107]\n",
      "[7.000000014901161, 8.499999970197678]\n",
      "[7.000000014901161, 8.499999970197678, 10.0799999833107, 9.819999933242798, 9.819999933242798, 9.819999933242798]\n",
      "[7.000000014901161, 8.499999970197678]\n",
      "[7.000000014901161, 8.499999970197678, 10.0799999833107, 10.0799999833107, 9.819999933242798, 10.0799999833107]\n",
      "[7.000000014901161, 8.499999970197678]\n",
      "[7.000000014901161, 8.499999970197678, 9.819999933242798, 9.819999933242798, 10.0799999833107, 9.819999933242798]\n",
      "[7.000000014901161, 8.499999970197678]\n",
      "[7.000000014901161, 8.499999970197678, 10.29999989271164, 10.0799999833107, 9.819999933242798, 10.0799999833107]\n",
      "[7.000000014901161, 8.499999970197678]\n",
      "[7.000000014901161, 8.499999970197678, 9.819999933242798, 9.819999933242798, 10.0799999833107, 9.819999933242798]\n",
      "[7.000000014901161, 8.499999970197678]\n",
      "[7.000000014901161, 8.499999970197678, 9.819999933242798, 9.819999933242798, 9.819999933242798, 9.819999933242798]\n",
      "[7.000000014901161, 8.499999970197678]\n",
      "[7.000000014901161, 8.499999970197678, 9.819999933242798, 9.819999933242798, 10.0799999833107, 10.0799999833107]\n",
      "[7.000000014901161, 8.499999970197678]\n",
      "[7.000000014901161, 8.499999970197678, 9.819999933242798, 9.719999939203262, 9.819999933242798, 10.0799999833107]\n",
      "[7.000000014901161, 8.499999970197678]\n",
      "[7.000000014901161, 8.499999970197678, 10.0799999833107, 9.819999933242798, 9.819999933242798, 10.119999915361404]\n",
      "[7.000000014901161, 8.499999970197678]\n",
      "[7.000000014901161, 8.499999970197678, 9.819999933242798, 9.819999933242798, 10.0799999833107, 9.819999933242798]\n",
      "[7.000000014901161, 8.499999970197678]\n",
      "[7.000000014901161, 8.499999970197678, 9.819999933242798, 9.819999933242798, 10.0799999833107, 9.819999933242798]\n",
      "[7.000000014901161, 8.499999970197678]\n",
      "[7.000000014901161, 8.499999970197678, 9.819999933242798, 9.819999933242798, 9.819999933242798, 9.819999933242798]\n",
      "[7.000000014901161, 8.499999970197678]\n",
      "[7.000000014901161, 8.499999970197678, 10.0799999833107, 9.819999933242798, 10.0799999833107, 9.819999933242798]\n",
      "[7.000000014901161, 8.499999970197678]\n",
      "[7.000000014901161, 8.499999970197678, 9.819999933242798, 9.819999933242798, 9.819999933242798, 9.819999933242798]\n",
      "[7.000000014901161, 8.499999970197678]\n",
      "[7.000000014901161, 8.499999970197678, 9.819999933242798, 9.819999933242798, 9.819999933242798, 9.819999933242798]\n",
      "[7.000000014901161, 8.499999970197678]\n",
      "[7.000000014901161, 8.499999970197678, 10.0799999833107, 9.819999933242798, 9.819999933242798, 9.819999933242798]\n",
      "[7.000000014901161, 8.499999970197678]\n",
      "[7.000000014901161, 8.499999970197678, 10.0799999833107, 9.819999933242798, 10.0799999833107, 9.819999933242798]\n",
      "[7.000000014901161, 8.499999970197678]\n",
      "[7.000000014901161, 8.499999970197678, 9.819999933242798, 9.819999933242798, 10.0799999833107, 9.819999933242798]\n",
      "[7.000000014901161, 8.499999970197678]\n",
      "[7.000000014901161, 8.499999970197678, 9.819999933242798, 9.4200000166893, 10.0799999833107, 10.0799999833107]\n",
      "[7.000000014901161, 8.499999970197678]\n",
      "[7.000000014901161, 8.26000002026558, 9.819999933242798, 10.0799999833107, 9.819999933242798, 9.819999933242798]\n",
      "[7.000000014901161, 8.26000002026558]\n",
      "[7.000000014901161, 7.519999995827675, 10.0799999833107, 9.780000030994415, 10.0799999833107, 9.819999933242798]\n",
      "[7.000000014901161, 7.519999995827675]\n",
      "[7.000000014901161, 7.519999995827675, 10.0799999833107, 10.0799999833107, 9.819999933242798, 9.819999933242798]\n",
      "[7.000000014901161, 7.519999995827675]\n",
      "[7.000000014901161, 7.519999995827675, 9.819999933242798, 9.819999933242798, 10.059999972581863, 9.819999933242798]\n",
      "[7.000000014901161, 7.519999995827675]\n",
      "[7.000000014901161, 7.519999995827675, 9.819999933242798, 9.819999933242798, 10.0799999833107, 10.0799999833107]\n",
      "[7.000000014901161, 7.519999995827675]\n",
      "[7.000000014901161, 7.519999995827675, 9.4200000166893, 10.0799999833107, 9.819999933242798, 10.0799999833107]\n",
      "[7.000000014901161, 7.519999995827675]\n",
      "[7.000000014901161, 7.519999995827675, 10.0799999833107, 13.880000114440918, 9.819999933242798, 9.819999933242798]\n",
      "[7.000000014901161, 7.519999995827675]\n",
      "[7.000000014901161, 7.519999995827675, 9.819999933242798, 9.879999965429306, 9.819999933242798, 9.819999933242798]\n",
      "[7.000000014901161, 7.519999995827675]\n",
      "[7.000000014901161, 7.519999995827675, 9.819999933242798, 9.819999933242798, 9.819999933242798, 9.819999933242798]\n",
      "[7.000000014901161, 7.519999995827675]\n",
      "[7.000000014901161, 7.519999995827675, 9.819999933242798, 9.819999933242798, 9.85999995470047, 10.0799999833107]\n",
      "[7.000000014901161, 7.519999995827675]\n",
      "[7.000000014901161, 7.519999995827675, 9.819999933242798, 9.819999933242798, 10.0799999833107, 9.819999933242798]\n",
      "[7.000000014901161, 7.519999995827675]\n",
      "[7.000000014901161, 7.519999995827675, 9.459999948740005, 10.03999999165535, 10.0799999833107, 9.819999933242798]\n",
      "[7.000000014901161, 7.519999995827675]\n",
      "[7.000000014901161, 7.519999995827675, 9.819999933242798, 10.0799999833107, 10.0799999833107, 10.0799999833107]\n",
      "[7.000000014901161, 7.519999995827675]\n",
      "[7.000000014901161, 7.519999995827675, 9.819999933242798, 10.0799999833107, 9.980000019073486, 9.819999933242798]\n",
      "[7.000000014901161, 7.519999995827675]\n",
      "[7.000000014901161, 7.519999995827675, 9.819999933242798, 9.619999945163727, 9.819999933242798, 10.0799999833107]\n",
      "[7.000000014901161, 7.519999995827675]\n",
      "[7.000000014901161, 7.519999995827675, 10.0799999833107, 9.819999933242798, 9.819999933242798, 9.819999933242798]\n",
      "[7.000000014901161, 7.519999995827675]\n",
      "[7.000000014901161, 7.519999995827675, 10.120000064373016, 10.120000004768372, 9.819999933242798, 9.819999933242798]\n",
      "[7.000000014901161, 7.519999995827675]\n",
      "[7.000000014901161, 7.519999995827675, 9.819999933242798, 10.0799999833107, 10.0799999833107, 9.819999933242798]\n",
      "[7.000000014901161, 7.519999995827675]\n",
      "[7.000000014901161, 7.519999995827675, 10.0799999833107, 9.819999933242798, 10.0799999833107, 9.940000116825104]\n",
      "[7.000000014901161, 7.519999995827675]\n",
      "[7.000000014901161, 7.519999995827675, 9.819999933242798, 9.819999933242798, 9.819999933242798, 9.819999933242798]\n",
      "[7.000000014901161, 7.519999995827675]\n",
      "[7.000000014901161, 7.519999995827675, 9.819999933242798, 9.819999933242798, 9.819999933242798, 10.0799999833107]\n",
      "[7.000000014901161, 7.519999995827675]\n",
      "[7.000000014901161, 7.519999995827675, 9.819999933242798, 10.0799999833107, 9.819999933242798, 9.940000116825104]\n",
      "[7.000000014901161, 7.519999995827675]\n"
     ]
    }
   ],
   "source": [
    "gen = 500\n",
    "for g in range(gen):\n",
    "    Smutab = []\n",
    "    Smu11 = mutation(Stab[0])\n",
    "    Smu12 = mutation(Stab[0])\n",
    "    Smu21 = mutation(Stab[1])\n",
    "    Smu22 = mutation(Stab[1])\n",
    "    Smutab.append(Smu11)\n",
    "    Smutab.append(Smu12)\n",
    "    Smutab.append(Smu21)\n",
    "    Smutab.append(Smu22)\n",
    "    #print(Smutab)\n",
    "    Lmutab = []\n",
    "    Lmutab.append(train(Smu11,SpikingMLP(sizes)))\n",
    "    Lmutab.append(train(Smu12,SpikingMLP(sizes)))\n",
    "    Lmutab.append(train(Smu21,SpikingMLP(sizes)))\n",
    "    Lmutab.append(train(Smu22,SpikingMLP(sizes)))\n",
    "    #print(Lmutab)\n",
    "    Ljointtab = Ltab + Lmutab\n",
    "    Sjointtab = Stab + Smutab\n",
    "    good_index = heapq.nsmallest(2,range(len(Ljointtab)), Ljointtab.__getitem__)\n",
    "    Stab = [Sjointtab[m] for m in good_index]\n",
    "    Ltab = [Ljointtab[n] for n in good_index]\n",
    "    if g % 10 == 0:\n",
    "        print(Ljointtab)\n",
    "        print(Ltab)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[tensor([[1, 2, 2],\n",
      "        [1, 0, 1],\n",
      "        [0, 2, 2],\n",
      "        [1, 1, 0],\n",
      "        [2, 1, 2],\n",
      "        [0, 3, 0],\n",
      "        [2, 3, 2],\n",
      "        [1, 1, 3]], dtype=torch.int32), 0], [tensor([[1, 1, 1],\n",
      "        [0, 2, 0],\n",
      "        [2, 1, 2],\n",
      "        [1, 2, 0],\n",
      "        [2, 3, 3],\n",
      "        [1, 2, 2],\n",
      "        [2, 1, 0],\n",
      "        [2, 1, 3]], dtype=torch.int32), 5]]\n"
     ]
    }
   ],
   "source": [
    "print(Stab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 1., 1., 1., 0., 0., 1., 1., 0.], grad_fn=<CatBackward>)\n",
      "tensor(0.9000, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "sizes = [2,5,1]\n",
    "snn = SpikingMLP(sizes)\n",
    "snn.reset()\n",
    "\n",
    "decay = 0.5\n",
    "alpha = 1\n",
    "trace1 = 0\n",
    "trace2 = 0\n",
    "trace3 = 0\n",
    "\n",
    "loss = torch.nn.MSELoss()\n",
    "\n",
    "prediction = torch.Tensor()\n",
    "for i in range(10):\n",
    "    #print(i)\n",
    "    trace1 = trace1 * decay + alpha * x[i]\n",
    "    #print(snn.states[0])\n",
    "    output = snn(x[i])\n",
    "    prediction = torch.cat((prediction,output))\n",
    "    trace2 = trace2 * decay + alpha * snn.states[0][0]\n",
    "    trace3 = trace3 * decay + alpha * snn.states[1][0]\n",
    "    #print('x:',x[i])\n",
    "    #print(snn.states[0])\n",
    "#print(trace1,trace2,trace3)\n",
    "print(prediction)\n",
    "print(loss(prediction,y[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network\n",
    "sizes = [2, 5, 1]\n",
    "snn = SpikingMLP(sizes)\n",
    "\n",
    "# Loss function and optimizer\n",
    "def most_basic_loss_ever(x, y):\n",
    "    return (x.view(-1) - y.view(-1)).abs().sum()  # ensure both are flat\n",
    "\n",
    "criterion = most_basic_loss_ever\n",
    "optimizer = optim.Adam(snn.parameters())\n",
    "\n",
    "# Batch size of 100, 2 epochs\n",
    "batch = 100\n",
    "epochs = 3\n",
    "\n",
    "def train(S,snn):\n",
    "    losses = []\n",
    "    for e in range(epochs):\n",
    "        for i in range(samples // batch):\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            for p in snn.parameters():\n",
    "                p.grad = None\n",
    "            \n",
    "            # Reset the network\n",
    "            snn.reset()\n",
    "\n",
    "            # Forward + backward + optimize\n",
    "            y_hat = snn(x[i:i + batch])\n",
    "            #print(list(snn.parameters()))\n",
    "            loss = criterion(y_hat, y[i:i + batch])\n",
    "            trace1, trace2, trace3 = get_trace(x[i:i + batch],snn.states[0][0],snn.states[1][0])\n",
    "            w1,w2 = update_weight(S, trace1, trace2, trace3, (1/(loss.item()+0.01)))\n",
    "            for i,w in enumerate(snn.parameters()):\n",
    "                if i == 0:\n",
    "                    w.data = w1 + w.data\n",
    "                else:\n",
    "                    w.data = w2 + w.data\n",
    "\n",
    "            # Print statistics\n",
    "            losses.append(loss.item())\n",
    "            #print(f\"[{e + 1}, {i}] loss: {loss.item()}\")\n",
    "    return min(losses)\n",
    "\n",
    "#train(mutation(S))\n",
    "\n",
    "#print('Finished Training')\n",
    "\n",
    "#plt.plot(losses)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.0\n",
      "[Parameter containing:\n",
      "tensor([[-0.3738, -0.3887],\n",
      "        [13.5311, 13.8867],\n",
      "        [13.1364, 12.7798],\n",
      "        [-0.4300, -0.4871],\n",
      "        [ 0.1038, -0.2728]], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.2200,  0.2119, -0.2160, -0.3945,  0.0668]], requires_grad=True)]\n",
      "18.0\n",
      "[Parameter containing:\n",
      "tensor([[329.4209, 523.0168],\n",
      "        [329.2086, 524.1368],\n",
      "        [328.8070, 523.6957],\n",
      "        [328.1838, 523.1481],\n",
      "        [329.5231, 524.0338]], requires_grad=True), Parameter containing:\n",
      "tensor([[829.4711, 827.4448, 828.0056, 827.7215, 827.9511]],\n",
      "       requires_grad=True)]\n",
      "18.0\n",
      "[Parameter containing:\n",
      "tensor([[252.2332, 339.0680],\n",
      "        [251.8015, 338.3237],\n",
      "        [252.3256, 339.1833],\n",
      "        [251.9291, 338.7458],\n",
      "        [252.8493, 338.3752]], requires_grad=True), Parameter containing:\n",
      "tensor([[464.6884, 462.7307, 463.8718, 463.2959, 465.1858]],\n",
      "       requires_grad=True)]\n",
      "45.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.0946,  0.0338],\n",
      "        [ 0.0810,  0.0420],\n",
      "        [-0.2813, -0.1417],\n",
      "        [ 0.1639,  0.3869],\n",
      "        [-0.4186,  0.9270]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1797, 0.5040, 0.6342, 0.1170, 0.1588]], requires_grad=True)]\n",
      "18.0\n",
      "[Parameter containing:\n",
      "tensor([[485.8512, 485.7083],\n",
      "        [499.6157, 499.0247],\n",
      "        [496.4070, 496.8715],\n",
      "        [479.2525, 479.1316],\n",
      "        [496.1048, 497.0387]], requires_grad=True), Parameter containing:\n",
      "tensor([[489.8854, 490.0014, 490.0554, 490.2525, 489.4248]],\n",
      "       requires_grad=True)]\n",
      "45.0\n",
      "[Parameter containing:\n",
      "tensor([[-0.6496,  0.1454],\n",
      "        [-0.5225,  0.0507],\n",
      "        [-0.5228, -0.6203],\n",
      "        [-0.1881, -0.3963],\n",
      "        [-0.5414,  0.2361]], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.2331, -0.3969, -0.2157, -0.0322, -0.2200]], requires_grad=True)]\n",
      "18.0\n",
      "[Parameter containing:\n",
      "tensor([[505.0049, 676.8794],\n",
      "        [504.3957, 677.1968],\n",
      "        [504.9696, 677.3015],\n",
      "        [504.7590, 677.2139],\n",
      "        [504.4601, 677.1085]], requires_grad=True), Parameter containing:\n",
      "tensor([[927.2134, 927.6943, 927.8167, 927.6641, 929.3983]],\n",
      "       requires_grad=True)]\n",
      "45.0\n",
      "[Parameter containing:\n",
      "tensor([[ 0.1715, -0.1197],\n",
      "        [-0.1558, -0.8628],\n",
      "        [-0.1729, -0.0216],\n",
      "        [-0.0368,  0.4875],\n",
      "        [-0.0077,  0.3596]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.1582, 0.5707, 0.1572, 0.5406, 0.6321]], requires_grad=True)]\n",
      "45.0\n",
      "[Parameter containing:\n",
      "tensor([[ -7.6316,  -9.1380],\n",
      "        [ -7.4438, -10.2531],\n",
      "        [ -7.2340,  -9.5160],\n",
      "        [ -7.9599, -10.1624],\n",
      "        [ -8.1254, -10.2649]], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0072, -0.2897, -0.2873,  0.1518,  0.4428]], requires_grad=True)]\n",
      "18.0\n",
      "[Parameter containing:\n",
      "tensor([[749.3566, 835.1272],\n",
      "        [748.6465, 835.3339],\n",
      "        [752.1155, 837.2397],\n",
      "        [751.9764, 838.3834],\n",
      "        [749.6376, 836.4091]], requires_grad=True), Parameter containing:\n",
      "tensor([[961.7273, 961.3855, 963.9470, 963.4652, 962.8632]],\n",
      "       requires_grad=True)]\n",
      "45.0\n",
      "[Parameter containing:\n",
      "tensor([[-0.0936,  0.0577],\n",
      "        [ 0.4967, -0.2040],\n",
      "        [-0.3637, -0.2801],\n",
      "        [ 0.6663,  0.6795],\n",
      "        [-0.1394, -0.5530]], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.2846,  0.3045,  0.3467, -0.1917, -0.1245]], requires_grad=True)]\n",
      "45.0\n",
      "[Parameter containing:\n",
      "tensor([[-4.2922e-01, -6.5934e-01],\n",
      "        [ 1.7245e-01,  2.2527e-01],\n",
      "        [ 2.3672e-01, -4.4841e-02],\n",
      "        [ 2.3238e+02,  1.7213e+02],\n",
      "        [ 2.3206e+02,  1.7186e+02]], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0167,  0.3437, -0.0917,  0.1821, -0.3282]], requires_grad=True)]\n",
      "18.0\n",
      "[Parameter containing:\n",
      "tensor([[25.8672, 26.5047],\n",
      "        [24.4372, 24.5333],\n",
      "        [25.1761, 26.2284],\n",
      "        [-0.5237,  0.4144],\n",
      "        [-0.6668, -0.1890]], requires_grad=True), Parameter containing:\n",
      "tensor([[25.4379, 25.3977, 25.6817, 25.2950, 25.4397]], requires_grad=True)]\n",
      "20.0\n",
      "[Parameter containing:\n",
      "tensor([[-42.7015,  43.6808],\n",
      "        [-42.8042,  43.6600],\n",
      "        [-42.4441,  43.1327],\n",
      "        [-42.2905,  42.6922],\n",
      "        [-42.7159,  43.3638]], requires_grad=True), Parameter containing:\n",
      "tensor([[1.1925, 0.6886, 1.5866, 1.2757, 1.0962]], requires_grad=True)]\n",
      "45.0\n",
      "[Parameter containing:\n",
      "tensor([[-0.3117,  0.4608],\n",
      "        [-0.6340,  0.3514],\n",
      "        [ 0.2024,  0.4261],\n",
      "        [-0.1113,  0.4184],\n",
      "        [-0.2412,  0.3433]], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.4067, -0.1226,  0.3187,  0.0920,  0.0267]], requires_grad=True)]\n",
      "20.0\n",
      "[Parameter containing:\n",
      "tensor([[-0.1797,  0.5328],\n",
      "        [-0.3234,  0.1594],\n",
      "        [ 0.2964, -0.6035],\n",
      "        [ 0.5492, -0.4358],\n",
      "        [ 0.5123, -0.6066]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.9578, 0.6638, 1.2525, 0.7217, 1.0944]], requires_grad=True)]\n",
      "18.0\n",
      "[Parameter containing:\n",
      "tensor([[1214.8638, 1301.4922],\n",
      "        [1217.4786, 1303.4474],\n",
      "        [1217.6427, 1303.1479],\n",
      "        [1214.6333, 1300.4808],\n",
      "        [1215.3423, 1300.9104]], requires_grad=True), Parameter containing:\n",
      "tensor([[1427.6248, 1428.5939, 1428.3453, 1427.1136, 1426.8387]],\n",
      "       requires_grad=True)]\n",
      "45.0\n",
      "[Parameter containing:\n",
      "tensor([[ 8.2839e+02,  8.2892e+02],\n",
      "        [-5.6077e-01, -3.8036e-01],\n",
      "        [-6.4638e-01, -3.6569e-01],\n",
      "        [ 8.3162e+02,  8.3087e+02],\n",
      "        [-1.0123e-01, -2.4829e-01]], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0973, -0.2268, -0.3949,  0.3952,  0.2475]], requires_grad=True)]\n",
      "30.0\n",
      "[Parameter containing:\n",
      "tensor([[-521.4781, -693.4028],\n",
      "        [-521.0280, -693.6124],\n",
      "        [-520.3259, -692.9593],\n",
      "        [-521.0907, -694.0430],\n",
      "        [-521.2278, -694.0545]], requires_grad=True), Parameter containing:\n",
      "tensor([[16.5411, 17.1521, 12.2607, 16.4551, 16.5564]], requires_grad=True)]\n",
      "21.0\n",
      "[Parameter containing:\n",
      "tensor([[-0.3651, -0.5715],\n",
      "        [-0.1591,  0.3584],\n",
      "        [ 0.2430,  0.3385],\n",
      "        [ 0.4824,  0.0068],\n",
      "        [-0.1186,  0.1698]], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0021, -0.3895,  0.3121, -0.1638, -0.0520]], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "population = 20\n",
    "Ltab = []\n",
    "for p in range(population):\n",
    "    internal = create_node()\n",
    "    node_index = torch.randint(len(internal),(1,1)).item()\n",
    "    S = [internal,node_index]\n",
    "    snn = SpikingMLP(sizes)\n",
    "    L = train(S,snn)\n",
    "    print(L)\n",
    "    print(list(snn.parameters()))\n",
    "    Ltab.append(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 5, 1, 4, 6]\n",
      "[2, 0]\n",
      "[1, 3]\n"
     ]
    }
   ],
   "source": [
    "e = [3,5]\n",
    "f = [1,4,6]\n",
    "joint = e+f\n",
    "print(joint)\n",
    "good_index = heapq.nsmallest(2,range(len(joint)), joint.__getitem__)\n",
    "print(good_index)\n",
    "parents = [joint[m] for m in good_index]\n",
    "print(parents)\n",
    "#for i in f:\n",
    "    #if i<e[0]:\n",
    "        #e[0] = i\n",
    "    #else:\n",
    "        #if i<e[1]:\n",
    "            #e[1] = i\n",
    "    #print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 0.5049, -0.5355],\n",
      "        [-0.6936,  0.8443],\n",
      "        [ 0.0882, -0.3541],\n",
      "        [ 0.3409,  0.5484],\n",
      "        [ 0.2396, -0.7130]], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.3296,  0.2162, -0.1045,  0.3895,  0.4227]], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "weights = list(snn.parameters())\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [0., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 0.],\n",
      "        [1., 1.],\n",
      "        [0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randint(2, (samples, 2)).float()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 1., 0., 1.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 1.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]], grad_fn=<SpikeFunctionBackward>)\n"
     ]
    }
   ],
   "source": [
    "y_hat = snn(x)\n",
    "print(snn.states[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.9038, 0.5303]) tensor([1.9766, 0.0000, 0.0000, 0.0000, 1.9766], grad_fn=<AddBackward0>) tensor([1.9766], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "decay = 0.5\n",
    "alpha = 1\n",
    "def update_trace(prespike:torch.Tensor):\n",
    "    trace = 0\n",
    "    for i in range(prespike.size()[0]):\n",
    "        trace = trace * decay + alpha * prespike[i]           \n",
    "    return trace\n",
    "\n",
    "def get_trace(layer1,layer2,layer3):\n",
    "    trace1 = update_trace(layer1)\n",
    "    trace2 = update_trace(layer2)\n",
    "    trace3 = update_trace(layer3)\n",
    "    return trace1, trace2, trace3\n",
    "\n",
    "a,b,c = get_trace(x,snn.states[0][0],snn.states[1][0])  \n",
    "print(a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4258, 0.4902],\n",
      "        [0.4258, 0.4902],\n",
      "        [0.4902, 0.5547],\n",
      "        [0.4258, 0.4902],\n",
      "        [0.9160, 0.9805]], grad_fn=<CopySlices>)\n",
      "tensor([[0.0000, 0.0000, 0.0645, 0.0000, 0.4902]], grad_fn=<CopySlices>)\n",
      "[Parameter containing:\n",
      "tensor([[0.4258, 0.4902],\n",
      "        [0.4258, 0.4902],\n",
      "        [0.4902, 0.5547],\n",
      "        [0.4258, 0.4902],\n",
      "        [0.9160, 0.9805]], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.2868, -0.8998, -1.0204, -0.0059,  0.0199]], requires_grad=True)]\n",
      "[Parameter containing:\n",
      "tensor([[0.4258, 0.4902],\n",
      "        [0.4258, 0.4902],\n",
      "        [0.4902, 0.5547],\n",
      "        [0.4258, 0.4902],\n",
      "        [0.9160, 0.9805]], requires_grad=True), Parameter containing:\n",
      "tensor([[0.0000, 0.0000, 0.0645, 0.0000, 0.4902]], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "w1 = torch.zeros_like(list(snn.parameters())[0])\n",
    "for i in range(w1.size()[1]):\n",
    "    for j in range(w1.size()[0]):\n",
    "        w1[j][i] = a[i] + b[j]\n",
    "#print(w1)\n",
    "\n",
    "w2 = torch.zeros_like(list(snn.parameters())[1])\n",
    "for i in range(w2.size()[1]):\n",
    "    for j in range(w2.size()[0]):\n",
    "        w2[j][i] = b[i] + c[j] \n",
    "#print(w2)\n",
    "\n",
    "#print(list(snn.parameters()))\n",
    "for i,w in enumerate(snn.parameters()):\n",
    "    if i == 0:\n",
    "        w.data = w1\n",
    "    else:\n",
    "        w.data = w2\n",
    "#print(list(snn.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_operand = 3 #number of operands\n",
    "n_row = 4 #number of rows\n",
    "n_column = 2 #number of columns of internal nodes\n",
    "n_F = len(F) #number of operators\n",
    "\n",
    "def create_node():\n",
    "        internal1 = torch.cat((torch.randint(n_F,(n_row,1)),torch.randint(n_operand,(n_row,n_column))),1)\n",
    "        internal2 = torch.cat((torch.randint(n_F,(n_row,1)),torch.randint(n_row,(n_row,n_column))),1)\n",
    "        internal = torch.cat((internal1,internal2))\n",
    "        return internal\n",
    "\n",
    "internal = create_node()\n",
    "\n",
    "node_index = torch.randint(len(internal),(1,1)).item()\n",
    "\n",
    "S = [internal,node_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute(S,operand):\n",
    "        pheno = S[0]\n",
    "        i = S[1]\n",
    "        def compute1(i):\n",
    "                operator = F[pheno[i][0]]\n",
    "                output = operator(operand[pheno[i][1]],operand[pheno[i][2]])\n",
    "                return output\n",
    "        if i < n_row:\n",
    "                output = compute1(i)\n",
    "        else:\n",
    "                operator = F[pheno[i][0]]\n",
    "                output = operator(compute1(pheno[i][1]), compute1(pheno[i][2]))\n",
    "        return output\n",
    "\n",
    "def mutation(S):\n",
    "        mu = torch.randn((8,3))#*0.3\n",
    "        #mu = torch.clamp(mu, -1, 1) + 1\n",
    "        mutated_internal = torch.round(S[0]+mu)\n",
    "        l1 = torch.FloatTensor([[0, 0, 0]])\n",
    "        u1 = torch.FloatTensor([[3, 2, 2]])\n",
    "        mutated_internal[:4] = torch.max(torch.min(mutated_internal[:4], u1), l1)\n",
    "        l2 = torch.FloatTensor([[0, 2, 2]])\n",
    "        u2 = torch.FloatTensor([[3, 3, 3]])\n",
    "        mutated_internal[4:] = torch.max(torch.min(mutated_internal[4:], u2), l2)\n",
    "        mutated_internal = mutated_internal.int()\n",
    "        mutated_node_index = torch.randint(len(internal),(1,1)).item()\n",
    "        mutated_S = [mutated_internal,mutated_node_index]\n",
    "        return mutated_S"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
